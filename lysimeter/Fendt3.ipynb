{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "090a65f6",
   "metadata": {},
   "source": [
    "# Fendt Site\n",
    "## Create metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8a7868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import glob\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0313af4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/Gr_P_ET_DRAIN_2012-2014.csv', './data/FE1_P_ET_DRAIN_2012-2014.csv', './data/FE3_P_ET_DRAIN_2012-2014.csv', './data/FE2_P_ET_DRAIN_2012-2014.csv']\n"
     ]
    }
   ],
   "source": [
    "flist = glob.glob('./data/*.csv')\n",
    "print(flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eee79d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOY</th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>station</th>\n",
       "      <th>num_lys</th>\n",
       "      <th>ID_lys</th>\n",
       "      <th>origin_lys</th>\n",
       "      <th>man</th>\n",
       "      <th>station_man</th>\n",
       "      <th>EVAP_mm</th>\n",
       "      <th>PREC_mm</th>\n",
       "      <th>DRAIN_mm\\n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>Fe3</td>\n",
       "      <td>L1</td>\n",
       "      <td>Fe_3-1</td>\n",
       "      <td>Gr15</td>\n",
       "      <td>int</td>\n",
       "      <td>Fe_int</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.43</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>Fe3</td>\n",
       "      <td>L1</td>\n",
       "      <td>Fe_3-1</td>\n",
       "      <td>Gr15</td>\n",
       "      <td>int</td>\n",
       "      <td>Fe_int</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>Fe3</td>\n",
       "      <td>L1</td>\n",
       "      <td>Fe_3-1</td>\n",
       "      <td>Gr15</td>\n",
       "      <td>int</td>\n",
       "      <td>Fe_int</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>Fe3</td>\n",
       "      <td>L1</td>\n",
       "      <td>Fe_3-1</td>\n",
       "      <td>Gr15</td>\n",
       "      <td>int</td>\n",
       "      <td>Fe_int</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>Fe3</td>\n",
       "      <td>L1</td>\n",
       "      <td>Fe_3-1</td>\n",
       "      <td>Gr15</td>\n",
       "      <td>int</td>\n",
       "      <td>Fe_int</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.28</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6571</th>\n",
       "      <td>361</td>\n",
       "      <td>2014-12-27</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "      <td>Fe3</td>\n",
       "      <td>L6</td>\n",
       "      <td>Fe_3-6</td>\n",
       "      <td>Fe6</td>\n",
       "      <td>int</td>\n",
       "      <td>Fe_int</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6572</th>\n",
       "      <td>362</td>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "      <td>Fe3</td>\n",
       "      <td>L6</td>\n",
       "      <td>Fe_3-6</td>\n",
       "      <td>Fe6</td>\n",
       "      <td>int</td>\n",
       "      <td>Fe_int</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6573</th>\n",
       "      <td>363</td>\n",
       "      <td>2014-12-29</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "      <td>Fe3</td>\n",
       "      <td>L6</td>\n",
       "      <td>Fe_3-6</td>\n",
       "      <td>Fe6</td>\n",
       "      <td>int</td>\n",
       "      <td>Fe_int</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6574</th>\n",
       "      <td>364</td>\n",
       "      <td>2014-12-30</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "      <td>Fe3</td>\n",
       "      <td>L6</td>\n",
       "      <td>Fe_3-6</td>\n",
       "      <td>Fe6</td>\n",
       "      <td>int</td>\n",
       "      <td>Fe_int</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6575</th>\n",
       "      <td>365</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "      <td>Fe3</td>\n",
       "      <td>L6</td>\n",
       "      <td>Fe_3-6</td>\n",
       "      <td>Fe6</td>\n",
       "      <td>int</td>\n",
       "      <td>Fe_int</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6576 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DOY        date  day  month  year station num_lys  ID_lys origin_lys  \\\n",
       "0       1  2012-01-01    1      1  2012     Fe3      L1  Fe_3-1       Gr15   \n",
       "1       2  2012-01-02    2      1  2012     Fe3      L1  Fe_3-1       Gr15   \n",
       "2       3  2012-01-03    3      1  2012     Fe3      L1  Fe_3-1       Gr15   \n",
       "3       4  2012-01-04    4      1  2012     Fe3      L1  Fe_3-1       Gr15   \n",
       "4       5  2012-01-05    5      1  2012     Fe3      L1  Fe_3-1       Gr15   \n",
       "...   ...         ...  ...    ...   ...     ...     ...     ...        ...   \n",
       "6571  361  2014-12-27   27     12  2014     Fe3      L6  Fe_3-6        Fe6   \n",
       "6572  362  2014-12-28   28     12  2014     Fe3      L6  Fe_3-6        Fe6   \n",
       "6573  363  2014-12-29   29     12  2014     Fe3      L6  Fe_3-6        Fe6   \n",
       "6574  364  2014-12-30   30     12  2014     Fe3      L6  Fe_3-6        Fe6   \n",
       "6575  365  2014-12-31   31     12  2014     Fe3      L6  Fe_3-6        Fe6   \n",
       "\n",
       "      man station_man  EVAP_mm  PREC_mm  DRAIN_mm\\n  \n",
       "0     int      Fe_int     0.00     4.43        0.00  \n",
       "1     int      Fe_int     0.00     0.78        0.00  \n",
       "2     int      Fe_int     0.00     0.44        0.00  \n",
       "3     int      Fe_int     0.00    10.20        0.00  \n",
       "4     int      Fe_int     0.00    11.28        0.00  \n",
       "...   ...         ...      ...      ...         ...  \n",
       "6571  int      Fe_int     0.00     0.01        0.36  \n",
       "6572  int      Fe_int     0.16     0.42        0.15  \n",
       "6573  int      Fe_int     0.00     0.01        0.24  \n",
       "6574  int      Fe_int     0.00     0.02        0.29  \n",
       "6575  int      Fe_int      NaN      NaN         NaN  \n",
       "\n",
       "[6576 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = './data/FE3_P_ET_DRAIN_2012-2014.csv'\n",
    "\n",
    "with open(fname, 'r') as f:\n",
    "    s = StringIO()\n",
    "    s.write(f.read())\n",
    "    s.seek(0)\n",
    "\n",
    "    desc = []\n",
    "\n",
    "    # first get the metadata\n",
    "    while True:\n",
    "        line = s.readline()\n",
    "        if line.startswith('#'):\n",
    "            desc.append(line)\n",
    "        else:\n",
    "            df = pd.read_csv(s, header=None)\n",
    "            df.columns = line.split(',')\n",
    "            break\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d23182e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Project \n",
      "##TERENO_2010-2018\n",
      "#Summary\n",
      "##Daily sums of precipitation, evapotranspiration, and drainage calculated from Lysimeter mass change measurements (minute data) of the TERENO preAlpine Observatory \n",
      "#Creator\n",
      "##Katrin Schneider\n",
      "#Creation Date (of data file)\n",
      "##2019-10-01\n",
      "#Site\n",
      "##Fendt3\n",
      "#Location \n",
      "##47.83243 lat., 11.06111 lon. WGS 84\n",
      "#Elevation\n",
      "##595\n",
      "#Quantity keyword\n",
      "##precipitation, evapotranspiration, drainage, lysimeter \n",
      "#UsageRights \n",
      "##\n"
     ]
    }
   ],
   "source": [
    "description = ''.join(desc)\n",
    "print(description.split('CC BY NC')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19151afd",
   "metadata": {},
   "source": [
    "## connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d288462",
   "metadata": {},
   "outputs": [],
   "source": [
    "UPLOAD = True\n",
    "CONNECTION = 'test_iso'\n",
    "#CONNECTION = 'default'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "526ebff4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: Engine(postgresql://postgres:***@localhost:5432/test_iso)\n"
     ]
    }
   ],
   "source": [
    "from metacatalog import api\n",
    "session = api.connect_database(CONNECTION)\n",
    "print('Using: %s' % session.bind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c534f1ea",
   "metadata": {},
   "source": [
    "### add person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a203247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<metacatalog.models.person.Person at 0x7fedc2f2f0a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author = api.find_person(session, first_name='Katrin', last_name='Schneider', return_iterator=True).first()\n",
    "\n",
    "# check if exists\n",
    "if author is None:\n",
    "    author = api.add_person(\n",
    "        session,\n",
    "        first_name='Katrin',\n",
    "        last_name='Schneider',\n",
    "        affiliation='Karlsruhe Institute of Technology (KIT)',\n",
    "    )\n",
    "\n",
    "author"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa0ef45",
   "metadata": {},
   "source": [
    "### license"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11d9d25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 Creative Commons Attribution-NonCommerical 4.0 International\n"
     ]
    }
   ],
   "source": [
    "license = api.find_license(session, short_title='CC BY-NC 4.0')[0]\n",
    "\n",
    "print(license.id, license.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8528bdfd",
   "metadata": {},
   "source": [
    "### Keywords\n",
    "\n",
    "> #Quantity keyword\n",
    "> ##precipitation, evapotranspiration, drainage, lysimeter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96273458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1532e590-a62d-46e3-8d03-2351bc48166a EARTH SCIENCE > ATMOSPHERE > PRECIPITATION\n",
      "26fc4850-7ba9-44d8-a156-5c623e17b72f EARTH SCIENCE > ATMOSPHERE > ATMOSPHERIC WATER VAPOR > WATER VAPOR PROCESSES > EVAPOTRANSPIRATION\n",
      "6a2107ab-38ab-42dc-beb0-8ba5f65e8022 EARTH SCIENCE > TERRESTRIAL HYDROSPHERE > GROUND WATER > GROUND WATER PROCESSES/MEASUREMENTS > DRAINAGE\n",
      "269c7277-fa8f-4c1c-bd8b-ab772c1df4e5 EARTH SCIENCE > TERRESTRIAL HYDROSPHERE > SURFACE WATER > SURFACE WATER PROCESSES/MEASUREMENTS > DRAINAGE\n"
     ]
    }
   ],
   "source": [
    "for k in api.find_keyword(session, value='PRECIPITATION'):\n",
    "    print(k.uuid, k.full_path)\n",
    "\n",
    "for k in api.find_keyword(session, value='EVAPOTRANSPIRATION'):\n",
    "    print(k.uuid, k.full_path)\n",
    "\n",
    "for k in api.find_keyword(session, value='DRAINAGE'):\n",
    "    print(k.uuid, k.full_path)\n",
    "\n",
    "for k in api.find_keyword(session, value='LYSIMETER'):\n",
    "    print(k.uuid, k.full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f3748a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'daily rainfall sum': 115, 'evapotranspiration': 6319, 'drainage': 7328}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use uuids from above\n",
    "keyword_uuids = ('1532e590-a62d-46e3-8d03-2351bc48166a', '26fc4850-7ba9-44d8-a156-5c623e17b72f', '269c7277-fa8f-4c1c-bd8b-ab772c1df4e5')\n",
    "variables = ['daily rainfall sum', 'evapotranspiration', 'drainage']\n",
    "keywords = {}\n",
    "\n",
    "for uuid, var in zip(keyword_uuids, variables):\n",
    "    k = api.find_keyword(session, uuid=uuid, return_iterator=True).one()\n",
    "    keywords[var] = k.id\n",
    "\n",
    "keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13d5076",
   "metadata": {},
   "source": [
    "### location, abstract and title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b863e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = 'SRID=4326;POINT (11.06111 47.83243)'\n",
    "group_title = 'Fendt 3 TERENO preAlpine Observatory / SUSALPS'\n",
    "title = 'Fendt 3 lysimeter %s' \n",
    "\n",
    "abstract = \"\"\"\n",
    "Summary\n",
    "-------\n",
    "Daily sums of precipitation, evapotranspiration, and drainage calculated from Lysimeter mass change measurements\n",
    "(minute data) of the TERENO preAlpine Observatory\n",
    "\n",
    "Lineage statement \n",
    "-----------------\n",
    "data represents weight measurements of six large lysimsters (area 1m2, depth 1.4 m); evapotranspiration, precipitation and drainage at 1.4 m was calculated from these measurements\n",
    "the lysimeters are part of the TERENO preAlpine Observatory; two agricultural management systems are applied: extensive and intensive (refers to frequency and amount of slurry applications and cutting frequency)\n",
    "\n",
    "Processing of the ra data involves several steps:\n",
    "\n",
    "1. processing of .DBD files (rawdata files) into .TDM files with the National Instruments (NI) DIAdem software (version 2017 was used for the presented data): \n",
    "   NI DIAdem software reads in *.DBD files\n",
    "\n",
    "2. processing of the data using the Matlab script of Jin Fu.\n",
    "   Open the .TDM files in Excel and convert them into .xlsx files; Add-In “TDM” is required; the .TDM have to be opened with the TDM add-in, not with the standard Excel open or import menu! \n",
    "\n",
    "3. Apply the AWAT filter to the data to correct the data\n",
    "   the AWAT software is decribed in Peters et al 2017, http://dx.doi.org/10.1016/j.jhydrol.2017.04.015\n",
    "   data from 2018 has been preprocessed with the updated Version AWAT 3 -> use this version for new data\n",
    "   The settings can be adapted in the file “input.dat” (boundaries, moving window); also the file (rawdata1.dat, rawdata2.dat,…) has to be specified since each stands for one lysimeter1!\n",
    "   Run AWAT3.exe (formerly AWATexe); you will need one run per rawdataXX.dat file (i.e. each of the 6 rawdata files have to be specified in the ini file. \n",
    "\n",
    "4. Final check\n",
    "   data check for huge differences between the lysimeters of one hexagon: sometimes, weight measurements of single lysimeters seem to be erroneous (e.g. freezing, lysimeter sticks,…)\n",
    "   Snow correction: Weight measurements are erroneous under snow / frost conditions: \n",
    "   data are corrected according to snow cover (albedo > 0.5) as measured by nearby EC tower + visual check using the camara picture\n",
    "   lysimeter precipitation is replaced by pluvio / composite data when albedo is > 0.5 (using filter routine for albedo > 0.5 at 12:00 am)\n",
    "   for snow cover periods, ET data have been calculated with Penman-Monteith for 2012 -2014 and replaces with literature values for data from 2015 on\n",
    "   gap filling / data correction under snow free conditions: in case daily sums of ET and P values of one lysimeter differ much from other lysimeters (d\n",
    "\n",
    "Stations\n",
    "--------\n",
    "stations/sites of the lysimeter network: Graswang = Gr; Rottenbuch = Rb; Fendt1 = Fe1; Fendt2 = Fe2, Fendt3 = Fe3\n",
    " \n",
    "cloumn \"origin_lys\" indicates, where the soil columns come from; in the TERENO set-up, soil columns were transplanted from higher elevations to lower elevations to simulate the effects of higher temperatures on hydro-biogeochemical processes;\n",
    "lysimeters labelled \"GrX\" were transplanted from Graswang, those labelled with \"RbX\" were transplanted from Rottenbuch, and \"FeX\" indicate control lysimeters from Fendt; \n",
    "lysimeters at the Fendt site are equipped with soil columns from Graswang, Rottenbuch and Fendt (==control lysimeters); lysimeters at the Graswang site are only equipped with soils from Graswang (from three sites along the valley bottom); and lysimeters in Rottenbuch are euquipped with soil columns transplanted from Graswang and with soil columns from the Rottenbuch area (=control lysimeters)\n",
    "\n",
    "Data from 2012-2014 was prepared by Jin Fu; data correction and/or replacement of missing values for these data is unclear\n",
    "published in: Fu, J., Gasche, R., Wang, N., Lu, H., Butterbach-Bahl, K., Kiese, R., 2017. Impacts of climate and management on water balance and nitrogen leaching from montane grassland soils of S-Germany. Environ. Pollut. 229, 119–131. https://doi.org/10.1016/j.envpol.2017.05.071\n",
    "\n",
    "\n",
    "data correction and flags: under snow and/ or freezing conditions, the lysimeter weight measurements and the calculated evapotranspiration and precipitations values are prone to errors;\n",
    "therefore, calculated evapotranspiration was replaced with literature data and precipitations was replaced with composite data (from rain gauage or EC data)\n",
    "more details on data flags and replacement of measurements are available from the author\n",
    "\n",
    "information on lysimeter labels and origins of the soil columns are available from the author\n",
    "\n",
    "Variables (by column)\n",
    "---------------------\n",
    "\n",
    ".. note::\n",
    "    Not all columns are available for all sites\n",
    "\n",
    "ID_lys=lysimeter label as defined by UMS,\n",
    "DOY=day of year, date=YYYY-MM-DD, day, month, year,\n",
    "station=experimental site, num_lys=number of lysimeter,\n",
    "origin_lys=origin of lysimeter (either from other experimental site or from actual site),\n",
    "man=agricultural management (extensive or intensive),\n",
    "station_man= combined information on station and management,\n",
    "EVAP_mm=daily sum of evapotranspiration [mm],\n",
    "PREC_mm=daily sum of precipitation [mm],\n",
    "DRAIN_mm=daily sum of drainage [mm] (measured at 140 cm), \n",
    "cum_evap=cumulative evapotranspiration [mm],\n",
    "cum_prec=cumulative precipitation [mm],\n",
    "cum_drain=cumulative drainage [mm],\n",
    "exp_unit=experimental unit\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6cfa26",
   "metadata": {},
   "source": [
    "## derive the number of stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02dcf117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fe_3-1', 'Fe_3-2', 'Fe_3-3', 'Fe_3-4', 'Fe_3-5', 'Fe_3-6']\n"
     ]
    }
   ],
   "source": [
    "external_ids = df.ID_lys.unique().tolist()\n",
    "variables = ['daily rainfall sum', 'evapotranspiration', 'drainage']\n",
    "\n",
    "print(external_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4907e4bb",
   "metadata": {},
   "source": [
    "Adding the entires is a bit nested:\n",
    "\n",
    "- Entry for each variable\n",
    "- Composite for one Lysimeter\n",
    "- Label Group for Grasswang\n",
    "- Project for TERENO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56c35bb2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fe_3-1 daily rainfall sum\n",
      "Fe_3-1 evapotranspiration\n",
      "Fe_3-1 drainage\n",
      "Fe_3-2 daily rainfall sum\n",
      "Fe_3-2 evapotranspiration\n",
      "Fe_3-2 drainage\n",
      "Fe_3-3 daily rainfall sum\n",
      "Fe_3-3 evapotranspiration\n",
      "Fe_3-3 drainage\n",
      "Fe_3-4 daily rainfall sum\n",
      "Fe_3-4 evapotranspiration\n",
      "Fe_3-4 drainage\n",
      "Fe_3-5 daily rainfall sum\n",
      "Fe_3-5 evapotranspiration\n",
      "Fe_3-5 drainage\n",
      "Fe_3-6 daily rainfall sum\n",
      "Fe_3-6 evapotranspiration\n",
      "Fe_3-6 drainage\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "entries = []\n",
    "composites = []\n",
    "\n",
    "for ext_id in external_ids:\n",
    "    grp_entries = []\n",
    "    for var_name in variables:\n",
    "        entry = api.find_entry(session, external_id=ext_id, variable=var_name, return_iterator=True).first()\n",
    "        variable = api.find_variable(session, name=var_name)[0]\n",
    "    \n",
    "        # add if missing\n",
    "        if entry is None:\n",
    "            entry = api.add_entry(\n",
    "                session,\n",
    "                title=title % ext_id,\n",
    "                author=author.id,\n",
    "                location=location,\n",
    "                variable=variable.id,\n",
    "                abstract=abstract,\n",
    "                external_id=ext_id,\n",
    "                license=license,\n",
    "                embargo=True\n",
    "            )\n",
    "            # add keyword\n",
    "            api.add_keywords_to_entries(session, [entry], [keywords[var_name]])\n",
    "            \n",
    "        grp_entries.append(entry)\n",
    "        entries.append(entry)\n",
    "        \n",
    "    # check the composite\n",
    "    composite = api.find_group(session, title=title % ext_id, return_iterator=True).first()\n",
    "    if composite is None:\n",
    "        composite = api.add_group(\n",
    "            session,\n",
    "            group_type='Composite',\n",
    "            entry_ids=[e.id for e in grp_entries],\n",
    "            title=title % ext_id,\n",
    "            description=f'Full Lysimeter Record ID {ext_id}'\n",
    "        )\n",
    "    composites.append(composite)\n",
    "\n",
    "for e in entries:\n",
    "    print(e.external_id, e.variable.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b7a7a34",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<metacatalog.models.entrygroup.EntryGroup at 0x7fedc2f2eaa0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the label group\n",
    "group = api.find_group(session, title=group_title, return_iterator=True).first()\n",
    "\n",
    "if group is None:\n",
    "    group = api.add_group(\n",
    "        session,\n",
    "        group_type='Label',\n",
    "        entry_ids = [e.id for e in entries],\n",
    "        title=group_title,\n",
    "        description='All data from Fendt-1 of the TERENO preAlpine Observatory'\n",
    "    )\n",
    "\n",
    "group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f36aa7b",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bcdd826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOY</th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>station</th>\n",
       "      <th>num_lys</th>\n",
       "      <th>ID_lys</th>\n",
       "      <th>origin_lys</th>\n",
       "      <th>man</th>\n",
       "      <th>station_man</th>\n",
       "      <th>EVAP_mm</th>\n",
       "      <th>PREC_mm</th>\n",
       "      <th>DRAIN_mm\\n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>Fe3</td>\n",
       "      <td>L1</td>\n",
       "      <td>Fe_3-1</td>\n",
       "      <td>Gr15</td>\n",
       "      <td>int</td>\n",
       "      <td>Fe_int</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.43</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>Fe3</td>\n",
       "      <td>L1</td>\n",
       "      <td>Fe_3-1</td>\n",
       "      <td>Gr15</td>\n",
       "      <td>int</td>\n",
       "      <td>Fe_int</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>Fe3</td>\n",
       "      <td>L1</td>\n",
       "      <td>Fe_3-1</td>\n",
       "      <td>Gr15</td>\n",
       "      <td>int</td>\n",
       "      <td>Fe_int</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>Fe3</td>\n",
       "      <td>L1</td>\n",
       "      <td>Fe_3-1</td>\n",
       "      <td>Gr15</td>\n",
       "      <td>int</td>\n",
       "      <td>Fe_int</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>Fe3</td>\n",
       "      <td>L1</td>\n",
       "      <td>Fe_3-1</td>\n",
       "      <td>Gr15</td>\n",
       "      <td>int</td>\n",
       "      <td>Fe_int</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.28</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6571</th>\n",
       "      <td>361</td>\n",
       "      <td>2014-12-27</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "      <td>Fe3</td>\n",
       "      <td>L6</td>\n",
       "      <td>Fe_3-6</td>\n",
       "      <td>Fe6</td>\n",
       "      <td>int</td>\n",
       "      <td>Fe_int</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6572</th>\n",
       "      <td>362</td>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "      <td>Fe3</td>\n",
       "      <td>L6</td>\n",
       "      <td>Fe_3-6</td>\n",
       "      <td>Fe6</td>\n",
       "      <td>int</td>\n",
       "      <td>Fe_int</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6573</th>\n",
       "      <td>363</td>\n",
       "      <td>2014-12-29</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "      <td>Fe3</td>\n",
       "      <td>L6</td>\n",
       "      <td>Fe_3-6</td>\n",
       "      <td>Fe6</td>\n",
       "      <td>int</td>\n",
       "      <td>Fe_int</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6574</th>\n",
       "      <td>364</td>\n",
       "      <td>2014-12-30</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "      <td>Fe3</td>\n",
       "      <td>L6</td>\n",
       "      <td>Fe_3-6</td>\n",
       "      <td>Fe6</td>\n",
       "      <td>int</td>\n",
       "      <td>Fe_int</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6575</th>\n",
       "      <td>365</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "      <td>Fe3</td>\n",
       "      <td>L6</td>\n",
       "      <td>Fe_3-6</td>\n",
       "      <td>Fe6</td>\n",
       "      <td>int</td>\n",
       "      <td>Fe_int</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6576 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DOY        date  day  month  year station num_lys  ID_lys origin_lys  \\\n",
       "0       1  2012-01-01    1      1  2012     Fe3      L1  Fe_3-1       Gr15   \n",
       "1       2  2012-01-02    2      1  2012     Fe3      L1  Fe_3-1       Gr15   \n",
       "2       3  2012-01-03    3      1  2012     Fe3      L1  Fe_3-1       Gr15   \n",
       "3       4  2012-01-04    4      1  2012     Fe3      L1  Fe_3-1       Gr15   \n",
       "4       5  2012-01-05    5      1  2012     Fe3      L1  Fe_3-1       Gr15   \n",
       "...   ...         ...  ...    ...   ...     ...     ...     ...        ...   \n",
       "6571  361  2014-12-27   27     12  2014     Fe3      L6  Fe_3-6        Fe6   \n",
       "6572  362  2014-12-28   28     12  2014     Fe3      L6  Fe_3-6        Fe6   \n",
       "6573  363  2014-12-29   29     12  2014     Fe3      L6  Fe_3-6        Fe6   \n",
       "6574  364  2014-12-30   30     12  2014     Fe3      L6  Fe_3-6        Fe6   \n",
       "6575  365  2014-12-31   31     12  2014     Fe3      L6  Fe_3-6        Fe6   \n",
       "\n",
       "      man station_man  EVAP_mm  PREC_mm  DRAIN_mm\\n  \n",
       "0     int      Fe_int     0.00     4.43        0.00  \n",
       "1     int      Fe_int     0.00     0.78        0.00  \n",
       "2     int      Fe_int     0.00     0.44        0.00  \n",
       "3     int      Fe_int     0.00    10.20        0.00  \n",
       "4     int      Fe_int     0.00    11.28        0.00  \n",
       "...   ...         ...      ...      ...         ...  \n",
       "6571  int      Fe_int     0.00     0.01        0.36  \n",
       "6572  int      Fe_int     0.16     0.42        0.15  \n",
       "6573  int      Fe_int     0.00     0.01        0.24  \n",
       "6574  int      Fe_int     0.00     0.02        0.29  \n",
       "6575  int      Fe_int      NaN      NaN         NaN  \n",
       "\n",
       "[6576 rows x 14 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd75d7d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry ID 44 - daily rainfall sum: uploaded: 1093 points.\n",
      "Entry ID 45 - evapotranspiration: uploaded: 1093 points.\n",
      "Entry ID 46 - drainage: uploaded: 1093 points.\n",
      "Entry ID 47 - daily rainfall sum: uploaded: 1093 points.\n",
      "Entry ID 48 - evapotranspiration: uploaded: 1093 points.\n",
      "Entry ID 49 - drainage: uploaded: 1093 points.\n",
      "Entry ID 50 - daily rainfall sum: uploaded: 1093 points.\n",
      "Entry ID 51 - evapotranspiration: uploaded: 1093 points.\n",
      "Entry ID 52 - drainage: uploaded: 1093 points.\n",
      "Entry ID 53 - daily rainfall sum: uploaded: 1093 points.\n",
      "Entry ID 54 - evapotranspiration: uploaded: 1093 points.\n",
      "Entry ID 55 - drainage: uploaded: 1093 points.\n",
      "Entry ID 56 - daily rainfall sum: uploaded: 1093 points.\n",
      "Entry ID 57 - evapotranspiration: uploaded: 1093 points.\n",
      "Entry ID 58 - drainage: uploaded: 1093 points.\n",
      "Entry ID 59 - daily rainfall sum: uploaded: 1093 points.\n",
      "Entry ID 60 - evapotranspiration: uploaded: 1093 points.\n",
      "Entry ID 61 - drainage: uploaded: 1093 points.\n"
     ]
    }
   ],
   "source": [
    "MAP = {\n",
    "    'daily rainfall sum': 'PREC_mm', \n",
    "    'evapotranspiration': 'EVAP_mm',\n",
    "    'drainage': 'DRAIN_mm\\n'\n",
    "} \n",
    "\n",
    "for label, grp in df.groupby('ID_lys'):\n",
    "    # go for the data\n",
    "    for var_name, col_name in MAP.items():\n",
    "        # laod the entry\n",
    "        entry = api.find_entry(session, external_id=label, variable=var_name, return_iterator=True).one()\n",
    "        \n",
    "        # check if data is available\n",
    "        if entry.datasource:\n",
    "            print(f'Skipping Entry ID={entry.id} ({entry.variable.name}): has data.')\n",
    "        else:\n",
    "            data = grp[['date', col_name]].dropna()\n",
    "            data['tstamp'] = data.date.map(lambda d: dt.strptime(d, '%Y-%m-%d'))\n",
    "            data.drop('date', axis=1, inplace=True)\n",
    "            data.set_index('tstamp', inplace=True)\n",
    "            \n",
    "            \n",
    "            # create the datasource\n",
    "            if not data.empty:\n",
    "                entry.create_datasource(path='timeseries', type=1, datatype='timeseries', commit=True)\n",
    "                \n",
    "                # do the import\n",
    "                entry.import_data(data)\n",
    "                \n",
    "                # create scale\n",
    "                entry.datasource.create_scale(\n",
    "                    resolution='1d',\n",
    "                    extent=[data.index.min(), data.index.max()],\n",
    "                    support=1.0,\n",
    "                    scale_dimension='temporal'\n",
    "                )\n",
    "                print(f'Entry ID {entry.id} - {entry.variable.name}: uploaded: {len(data)} points.')\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wradlib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "4a6cca48d9dc54240b1120f997bc89567c6fdd4e63a089bb9c0f7621569d912d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
