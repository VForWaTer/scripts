{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6600a093",
   "metadata": {},
   "source": [
    "# Bühlot data preprocessing\n",
    "\n",
    "The purpose of this code is to read in all the collected data, sort it by their different variables and then safe it in the correct folder.\n",
    "By running this code ALL the collected data will be processed, not just the new data. Therefore all the previous sorted data will be overwritten. The sorted data will be safed in a folder named \"data_export\".\n",
    "\n",
    "This is a list of all the variables:\n",
    "- air temperature [°C]\n",
    "- bulk electric conductivity [dS/m]\n",
    "- ground water level [mm]\n",
    "- logger temperature [°C]\n",
    "- precipitation [mm]\n",
    "- river water level 1 []\n",
    "- river water level 2 []\n",
    "- river water level 4 []\n",
    "- volumetric water content [m^3/m^3; %]\n",
    "- water temperature [°C]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "808b1fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "from glob import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "758b3e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(filename, variable):\n",
    "    \"\"\"\n",
    "    This function preprocesses the raw data files for the needed variable.\n",
    "    It will seperate a data file into the different variables.\n",
    "    It reads in the raw data to then create a tabel with the columns that are needed. \n",
    "\n",
    "    \"\"\"    \n",
    "\n",
    "    if variable == 'precipitation':\n",
    "        \n",
    "        # read in raw data\n",
    "        df = pd.read_csv(filename, skiprows=1, na_values='Logged')\n",
    "        \n",
    "        # slice down to relevant columns\n",
    "        df = df.iloc[:, [1,3]].copy()\n",
    "\n",
    "        # rename columns\n",
    "        df.columns = ['tstamp', 'precipitation [mm]']\n",
    "        \n",
    "        # convert to datetime\n",
    "        try: \n",
    "            df['tstamp'] = pd.to_datetime(df['tstamp'], format='%m/%d/%y %I:%M:%S %p')\n",
    "            \n",
    "        except ValueError:\n",
    "            df['tstamp'] = pd.to_datetime(df['tstamp'], format='%d/%m/%y %H:%M:%S')\n",
    "            \n",
    "        #finally:\n",
    "            #df['tstamp'] = pd.to_datetime(df['tstamp'])\n",
    "        \n",
    "    elif variable == 'air temperature':\n",
    "        \n",
    "        # read in raw data\n",
    "        df = pd.read_csv(filename, skiprows=1, na_values='Logged')\n",
    "        \n",
    "        # slice down to relevant columns\n",
    "        df = df.iloc[:, [1,2]].copy()\n",
    "        \n",
    "        # rename columns\n",
    "        df.columns = ['tstamp', 'air temperature [°C]']\n",
    "        \n",
    "        # convert to datetime      \n",
    "        try: \n",
    "            df['tstamp'] = pd.to_datetime(df['tstamp'], format='%m/%d/%y %I:%M:%S %p')\n",
    "            \n",
    "        except ValueError:\n",
    "            df['tstamp'] = pd.to_datetime(df['tstamp'], format='%d/%m/%y %H:%M:%S')\n",
    "            \n",
    "        #finally:\n",
    "            #df['tstamp'] = pd.to_datetime(df['tstamp'])\n",
    "        \n",
    "    elif variable == 'Table1_VWC':\n",
    "        \n",
    "        # read in raw data from table 1\n",
    "        df = pd.read_csv(filename, skiprows=[1,2,3,4], na_values='Logged')\n",
    "\n",
    "        # slice down to relevant columns\n",
    "        df = df.iloc[:, [0,2]].copy()\n",
    "\n",
    "        # rename columns\n",
    "        df.columns = ['tstamp', 'volumetric water content [m^3/m^3; %]']\n",
    "        \n",
    "        # convert to datetime\n",
    "        df['tstamp'] = pd.to_datetime(df['tstamp'], format='%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "    elif variable == 'Table1_EC':\n",
    "        \n",
    "        # read in raw data from table 1\n",
    "        df = pd.read_csv(filename, skiprows=[1,2,3,4], na_values='Logged')\n",
    "\n",
    "        # slice down to relevant columns\n",
    "        df = df.iloc[:, [0,3]].copy()\n",
    "\n",
    "        # rename columns\n",
    "        df.columns = ['tstamp', 'bulk electric conductivity [dS/m]']\n",
    "        \n",
    "        # convert to datetime\n",
    "        df['tstamp'] = pd.to_datetime(df['tstamp'], format='%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "    elif variable == 'Table2_VWC':\n",
    "        \n",
    "        # read in raw data from table 2\n",
    "        df = pd.read_csv(filename, skiprows=[1,2,3,4], na_values='Logged')\n",
    "\n",
    "        # slice down to relevant columns\n",
    "        df = df.iloc[:, [0,3]].copy()\n",
    "\n",
    "        # rename columns\n",
    "        df.columns = ['tstamp', 'volumetric water content [m^3/m^3; %]']\n",
    "        \n",
    "        # convert to datetime\n",
    "        df['tstamp'] = pd.to_datetime(df['tstamp'], format='%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "    elif variable == 'Table2_EC':\n",
    "        \n",
    "        # read in raw data from table 2\n",
    "        df = pd.read_csv(filename, skiprows=[1,2,3,4], na_values='Logged')\n",
    "\n",
    "        # slice down to relevant columns\n",
    "        df = df.iloc[:, [0,4]].copy()\n",
    "\n",
    "        # rename columns\n",
    "        df.columns = ['tstamp', 'bulk electric conductivity [dS/m]']\n",
    "        \n",
    "        # convert to datetime\n",
    "        df['tstamp'] = pd.to_datetime(df['tstamp'], format='%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "    elif variable == 'ground water level':\n",
    "        \n",
    "        # read in raw data\n",
    "        df = pd.read_excel(filename, skiprows=[1,2,3,4,5,6,7,8,9,10,11], na_values='Logged')\n",
    "\n",
    "        # slice down to relevant columns\n",
    "        df = df.iloc[:, [1,4]].copy()\n",
    "\n",
    "        # rename columns\n",
    "        df.columns = ['tstamp', 'water height [mm]']\n",
    "        \n",
    "        # convert to datetime\n",
    "        df['tstamp'] = pd.to_datetime(df['tstamp'], format='%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "    elif variable == 'water temperature':\n",
    "        \n",
    "        # read in raw data\n",
    "        df = pd.read_excel(filename, skiprows=[1,2,3,4,5,6,7,8,9,10,11], na_values='Logged')\n",
    "\n",
    "        # slice down to relevant columns\n",
    "        df = df.iloc[:, [1,2]].copy()\n",
    "\n",
    "        # rename columns\n",
    "        df.columns = ['tstamp', 'water temperature [°C]']\n",
    "        \n",
    "        # convert to datetime\n",
    "        df['tstamp'] = pd.to_datetime(df['tstamp'], format='%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "    elif variable == 'logger temperature':\n",
    "        \n",
    "        # read in raw data\n",
    "        df = pd.read_excel(filename, skiprows=[1,2,3,4,5,6,7,8,9,10,11], na_values='Logged')\n",
    "\n",
    "        # slice down to relevant columns\n",
    "        df = df.iloc[:, [1,3]].copy()\n",
    "\n",
    "        # rename columns\n",
    "        df.columns = ['tstamp', 'logger temperature [°C]']\n",
    "        \n",
    "        # convert to datetime\n",
    "        df['tstamp'] = pd.to_datetime(df['tstamp'], format='%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "    elif variable == 'ground water level csv':\n",
    "        \n",
    "        # read in raw data\n",
    "        df = pd.read_csv(filename, na_values='Logged')\n",
    "\n",
    "        # slice down to relevant columns\n",
    "        df = df.iloc[:, [1,4]].copy()\n",
    "\n",
    "        # rename columns\n",
    "        df.columns = ['tstamp', 'water height [mm]']\n",
    "        \n",
    "        # convert to datetime\n",
    "        df['tstamp'] = pd.to_datetime(df['tstamp'], format='%d/%m/%Y %H:%M:%S')\n",
    "        \n",
    "    elif variable == 'water temperature csv':\n",
    "        \n",
    "        # read in raw data\n",
    "        df = pd.read_csv(filename, na_values='Logged')\n",
    "\n",
    "        # slice down to relevant columns\n",
    "        df = df.iloc[:, [1,2]].copy()\n",
    "\n",
    "        # rename columns\n",
    "        df.columns = ['tstamp', 'water temperature [°C]']\n",
    "        \n",
    "        # convert to datetime\n",
    "        df['tstamp'] = pd.to_datetime(df['tstamp'], format='%d/%m/%Y %H:%M:%S')\n",
    "        \n",
    "    elif variable == 'logger temperature csv':\n",
    "        \n",
    "        # read in raw data\n",
    "        df = pd.read_csv(filename, na_values='Logged')\n",
    "\n",
    "        # slice down to relevant columns\n",
    "        df = df.iloc[:, [1,3]].copy()\n",
    "\n",
    "        # rename columns\n",
    "        df.columns = ['tstamp', 'logger temperature [°C]']\n",
    "        \n",
    "        # convert to datetime\n",
    "        df['tstamp'] = pd.to_datetime(df['tstamp'], format='%d/%m/%Y %H:%M:%S')\n",
    "        \n",
    "    elif variable == 'river water level 1':\n",
    "        \n",
    "        # read in raw data\n",
    "        df = pd.read_csv(filename, na_values='Logged', sep=';', header=None)\n",
    "\n",
    "        # merge date with time\n",
    "        df['tstamp'] = df.iloc[:,0] + ' ' + df.iloc[:,1]\n",
    "\n",
    "        # rename columns\n",
    "        df.columns = ['date_str', 'time', 'river water level 1 []', 'tstamp']\n",
    "\n",
    "        # change the order of the columns\n",
    "        df = df[['tstamp', 'river water level 1 []']]\n",
    "        \n",
    "        # convert to datetime\n",
    "        df['tstamp'] = pd.to_datetime(df['tstamp'], format='%d.%m.%Y %H:%M')\n",
    "        \n",
    "    elif variable == 'river water level 2':\n",
    "        \n",
    "        # read in raw data\n",
    "        df = pd.read_csv(filename, na_values='Logged', sep=';', header=None)\n",
    "\n",
    "        # merge date with time\n",
    "        df['tstamp'] = df.iloc[:,0] + ' ' + df.iloc[:,1]\n",
    "\n",
    "        # rename columns\n",
    "        df.columns = ['date_str', 'time', 'river water level 2 []', 'tstamp']\n",
    "\n",
    "        # change the order of the columns\n",
    "        df = df[['tstamp', 'river water level 2 []']]\n",
    "        \n",
    "        # convert to datetime\n",
    "        df['tstamp'] = pd.to_datetime(df['tstamp'], format='%d.%m.%Y %H:%M')\n",
    "        \n",
    "    elif variable == 'river water level 4':\n",
    "        \n",
    "        # read in raw data\n",
    "        df = pd.read_csv(filename, na_values='Logged', sep=';', header=None)\n",
    "\n",
    "        # merge date with time\n",
    "        df['tstamp'] = df.iloc[:,0] + ' ' + df.iloc[:,1]\n",
    "\n",
    "        # rename columns\n",
    "        df.columns = ['date_str', 'time', 'river water level 4 []', 'tstamp']\n",
    "\n",
    "        # change the order of the columns\n",
    "        df = df[['tstamp', 'river water level 4 []']]\n",
    "        \n",
    "        # convert to datetime\n",
    "        df['tstamp'] = pd.to_datetime(df['tstamp'], format='%d.%m.%Y %H:%M')\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Variable is '{variable}', must be in ['precipitation', 'air temperature', 'Table1_VWC', 'Table1_EC', 'Table2_VWC', 'Table2_EC', 'ground water level', 'water temperature', 'logger temperature', 'ground water level csv', 'water temperature csv', 'logger temperature csv', 'river water level 1', 'river water level 2', 'river water level 4']\")\n",
    "    \n",
    "    # return preprocessed dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3751058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(variable):\n",
    "    \"\"\"\n",
    "    This function merges all the data for the assigned list. \n",
    "    Here it is one list for the variable \"air temperature\" and one for the variable \"precipitation\". \n",
    "    It also will create a list for the sensor \"Table1\" and one for the sensor \"Table2\".\n",
    "    It will sort the lists by datetime and then safe the files in the right folder.\n",
    "    \n",
    "    \"Table1\" and \"Table2\" are names from the data file volumetric water content. Each station has two sensors (\"Table1\" and \"Table2\"). \n",
    "    While the sensor from \"Table1\" is placed in a depth of 20 cm below the top edge of the ground, the other sensor \"Table2\" is placed in a \n",
    "    depth of 50 cm below the top edge of the ground.\n",
    "    \n",
    "    The abbreviations are:\n",
    "    AT = air temperature\n",
    "    P = precipitation\n",
    "    VWC_1 = volumetric water content of \"Table1\"\n",
    "    EC_1 = bulk electric conductivity of \"Table1\"\n",
    "    VWC_2 = volumetric water content of \"Table2\"\n",
    "    EC_2 = bulk electric conductivity of \"Table2\"\n",
    "    GWL = ground water level as a .xlsx file\n",
    "    WT = water temperature as a .xlsx file\n",
    "    LT = logger temperature as a .xlsx file\n",
    "    GWL_csv = ground water level as a .csv file\n",
    "    WT_csv = water temperature as a .csv file\n",
    "    LG_csv = logger temperature as a .csv file \n",
    "    RWL_1 = river water level from the first sensor\n",
    "    RWL_2 = river water level from the second sensor\n",
    "    RWL_4 = river water level from the third sensor - sensor is named with number 4 \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if variable == 'all_data_AT':\n",
    "        \n",
    "        # merge all_data\n",
    "        df_all_data_AT = pd.concat(all_data_AT, ignore_index=True)\n",
    "        \n",
    "        # sort by datetime\n",
    "        df_all_data_AT.sort_index(axis='index', inplace=False)\n",
    "        \n",
    "        # replace filename \n",
    "        filename_AT = filename.replace(\".csv\", \"_air_temperature.csv\")\n",
    "        \n",
    "        # safe file to csv in the right folder\n",
    "        df_all_data_AT.to_csv(f'data/data_export/air_temperature/{filename_AT}', index=False)\n",
    "        \n",
    "    elif variable == 'all_data_P':\n",
    "        \n",
    "        # merge all_data\n",
    "        df_all_data_P = pd.concat(all_data_P, ignore_index=True)\n",
    "        \n",
    "        # sort by datetime\n",
    "        df_all_data_P.sort_index(axis='index', inplace=False)\n",
    "        \n",
    "        # replace filename\n",
    "        filename_P = filename.replace(\".csv\", \"_precipitation.csv\")\n",
    "        \n",
    "        # safe file to csv in the right folder\n",
    "        df_all_data_P.to_csv(f'data/data_export/precipitation/{filename_P}', index=False)\n",
    "        \n",
    "    elif variable == 'all_data_VWC_1':\n",
    "        \n",
    "        # merge all_data\n",
    "        df_all_data_VWC_1 = pd.concat(all_data_VWC_1, ignore_index=True)\n",
    "        \n",
    "        # sort by datetime\n",
    "        df_all_data_VWC_1.sort_index(axis='index', inplace=False)\n",
    "        \n",
    "        # replace filename\n",
    "        filename_VWC_1 = filename.replace(\".dat\", \"_VWC.dat\")\n",
    "        \n",
    "        # safe file to csv in the right folder\n",
    "        df_all_data_VWC_1.to_csv(f'data/data_export/volumetric_water_content/{filename_VWC_1}', index=False)\n",
    "        \n",
    "    elif variable == 'all_data_EC_1':\n",
    "        \n",
    "        # merge all_data\n",
    "        df_all_data_EC_1 = pd.concat(all_data_EC_1, ignore_index=True)\n",
    "        \n",
    "        # sort by datetime\n",
    "        df_all_data_EC_1.sort_index(axis='index', inplace=False)\n",
    "        \n",
    "        # replace filename\n",
    "        filename_EC_1 = filename.replace(\".dat\", \"_EC.dat\")\n",
    "        \n",
    "        # safe file to csv in the right folder\n",
    "        df_all_data_EC_1.to_csv(f'data/data_export/bulk_electric_conductivity/{filename_EC_1}', index=False)\n",
    "        \n",
    "    elif variable == 'all_data_VWC_2':\n",
    "        \n",
    "        # merge all_data\n",
    "        df_all_data_VWC_2 = pd.concat(all_data_VWC_2, ignore_index=True)\n",
    "        \n",
    "        # sort by datetime\n",
    "        df_all_data_VWC_2.sort_index(axis='index', inplace=False)\n",
    "        \n",
    "        # replace filename\n",
    "        filename_VWC_2 = filename.replace(\".dat\", \"_VWC.dat\")\n",
    "        \n",
    "        # safe file to csv in the right folder\n",
    "        df_all_data_VWC_2.to_csv(f'data/data_export/volumetric_water_content/{filename_VWC_2}', index=False)\n",
    "        \n",
    "    elif variable == 'all_data_EC_2':\n",
    "        \n",
    "        # merge all_data\n",
    "        df_all_data_EC_2 = pd.concat(all_data_EC_2, ignore_index=True)\n",
    "        \n",
    "        # sort by datetime\n",
    "        df_all_data_EC_2.sort_index(axis='index', inplace=False)\n",
    "        \n",
    "        # replace filename\n",
    "        filename_EC_2 = filename.replace(\".dat\", \"_EC.dat\")\n",
    "        \n",
    "        # safe file to csv in the right folder\n",
    "        df_all_data_EC_2.to_csv(f'data/data_export/bulk_electric_conductivity/{filename_EC_2}', index=False)\n",
    "        \n",
    "    elif variable == 'all_data_GWL':\n",
    "        \n",
    "        # merge all_data\n",
    "        df_all_data_GWL = pd.concat(all_data_GWL, ignore_index=True)\n",
    "        \n",
    "        # sort by datetime\n",
    "        df_all_data_GWL.sort_index(axis='index', inplace=False)\n",
    "        \n",
    "        # replace filename\n",
    "        filename_GWL = filename.replace(\".xlsx\", \"_GWL.xlsx\")\n",
    "        \n",
    "        # safe file to csv in the right folder\n",
    "        df_all_data_GWL.to_excel(f'data/data_export/ground_water_level/{filename_GWL}', index=False)\n",
    "        \n",
    "    elif variable == 'all_data_WT':\n",
    "        \n",
    "        # merge all_data\n",
    "        df_all_data_WT = pd.concat(all_data_WT, ignore_index=True)\n",
    "        \n",
    "        # sort by datetime\n",
    "        df_all_data_WT.sort_index(axis='index', inplace=False)\n",
    "        \n",
    "        # replace filename\n",
    "        filename_WT = filename.replace(\".xlsx\", \"_WT.xlsx\")\n",
    "        \n",
    "        # safe file to csv in the right folder\n",
    "        df_all_data_WT.to_excel(f'data/data_export/water_temperature/{filename_WT}', index=False)\n",
    "        \n",
    "    elif variable == 'all_data_LT':\n",
    "        \n",
    "        # merge all_data\n",
    "        df_all_data_LT = pd.concat(all_data_LT, ignore_index=True)\n",
    "        \n",
    "        # sort by datetime\n",
    "        df_all_data_LT.sort_index(axis='index', inplace=False)\n",
    "        \n",
    "        # replace filename\n",
    "        filename_LT = filename.replace(\".xlsx\", \"_LT.xlsx\")\n",
    "        \n",
    "        # safe file to csv in the right folder\n",
    "        df_all_data_LT.to_excel(f'data/data_export/logger_temperature/{filename_LT}', index=False)\n",
    "        \n",
    "    elif variable == 'all_data_GWL_csv':\n",
    "        \n",
    "        # merge all_data\n",
    "        df_all_data_GWL_csv = pd.concat(all_data_GWL_csv, ignore_index=True)\n",
    "        \n",
    "        # sort by datetime\n",
    "        df_all_data_GWL_csv.sort_index(axis='index', inplace=False)\n",
    "        \n",
    "        # replace filename\n",
    "        filename_GWL_csv = filename.replace(\".csv\", \"_GWL.csv\")\n",
    "        \n",
    "        # safe file to csv in the right folder\n",
    "        df_all_data_GWL_csv.to_csv(f'data/data_export/ground_water_level/{filename_GWL_csv}', index=False)\n",
    "        \n",
    "    elif variable == 'all_data_WT_csv':\n",
    "        \n",
    "        # merge all_data\n",
    "        df_all_data_WT_csv = pd.concat(all_data_WT_csv, ignore_index=True)\n",
    "        \n",
    "        # sort by datetime\n",
    "        df_all_data_WT_csv.sort_index(axis='index', inplace=False)\n",
    "        \n",
    "        # replace filename\n",
    "        filename_WT_csv = filename.replace(\".csv\", \"_WT.csv\")\n",
    "        \n",
    "        # safe file to csv in the right folder\n",
    "        df_all_data_WT_csv.to_csv(f'data/data_export/water_temperature/{filename_WT_csv}', index=False)\n",
    "        \n",
    "    elif variable == 'all_data_LT_csv':\n",
    "        \n",
    "        # merge all_data\n",
    "        df_all_data_LT_csv = pd.concat(all_data_LT_csv, ignore_index=True)\n",
    "        \n",
    "        # sort by datetime\n",
    "        df_all_data_LT_csv.sort_index(axis='index', inplace=False)\n",
    "        \n",
    "        # replace filename\n",
    "        filename_LT_csv = filename.replace(\".csv\", \"_LT.csv\")\n",
    "        \n",
    "        # safe file to csv in the right folder\n",
    "        df_all_data_LT_csv.to_csv(f'data/data_export/logger_temperature/{filename_LT_csv}', index=False)\n",
    "        \n",
    "    elif variable == 'all_data_RWL_1':\n",
    "        \n",
    "        # merge all_data\n",
    "        df_all_data_RWL_1 = pd.concat(all_data_RWL_1, ignore_index=True)\n",
    "        \n",
    "        # sort by datetime\n",
    "        df_all_data_RWL_1.sort_index(axis='index', inplace=False)\n",
    "        \n",
    "        # replace filename\n",
    "        filename_RWL_1 = filename.replace(\".csv\", \"_RWL_1.csv\")\n",
    "        \n",
    "        # safe file to csv in the right folder\n",
    "        df_all_data_RWL_1.to_csv(f'data/data_export/river_water_level_1/{filename_RWL_1}', index=False)\n",
    "        \n",
    "    elif variable == 'all_data_RWL_2':\n",
    "        \n",
    "        # merge all_data\n",
    "        df_all_data_RWL_2 = pd.concat(all_data_RWL_2, ignore_index=True)\n",
    "        \n",
    "        # sort by datetime\n",
    "        df_all_data_RWL_2.sort_index(axis='index', inplace=False)\n",
    "        \n",
    "        # replace filename\n",
    "        filename_RWL_2 = filename.replace(\".csv\", \"_RWL_2.csv\")\n",
    "        \n",
    "        # safe file to csv in the right folder\n",
    "        df_all_data_RWL_2.to_csv(f'data/data_export/river_water_level_2/{filename_RWL_2}', index=False)\n",
    "        \n",
    "    elif variable == 'all_data_RWL_4':\n",
    "        \n",
    "        # merge all_data\n",
    "        df_all_data_RWL_4 = pd.concat(all_data_RWL_4, ignore_index=True)\n",
    "        \n",
    "        # sort by datetime\n",
    "        df_all_data_RWL_4.sort_index(axis='index', inplace=False)\n",
    "        \n",
    "        # replace filename\n",
    "        filename_RWL_4 = filename.replace(\".csv\", \"_RWL_4.csv\")\n",
    "        \n",
    "        # safe file to csv in the right folder\n",
    "        df_all_data_RWL_4.to_csv(f'data/data_export/river_water_level_4/{filename_RWL_4}', index=False)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Variable is '{variable}', must be in ['all_data_AT', 'all_data_P', 'all_data_VWC_1', 'all_data_EC_1', 'all_data_VWC_2', 'all_data_EC_2', 'all_data_GWL', 'all_data_WT', 'all_data_LT', 'all_data_GWL_csv', 'all_data_WT_csv', 'all_data_LT_csv', 'river water level 1', 'river water level 2', 'river water level 4']\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "05ab14ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all the different stations for precipitation and air temperature\n",
    "FILENAMES = ['Butschenberg.csv', 'Grundigklinik.csv', 'Hundseck.csv', 'Schafhof.csv', 'Schönbrunn.csv', 'Sportplatz.csv', \n",
    "             'Sternenberg-Schlammfang.csv', 'Schwabenquelle.csv', 'Winterberg.csv']\n",
    "\n",
    "# lists of all the different stations for soil moisture \n",
    "FILENAMES_DAT_1 = ['Schafhof1_Table1.dat', 'Schafhof5_Table1.dat']\n",
    "FILENAMES_DAT_2 = ['Schafhof1_Table2.dat', 'Schafhof5_Table2.dat']\n",
    "\n",
    "# list of all the different stations for ground water level as a xlsx file\n",
    "FILENAMES_GWL = ['Schafhof_Tensiometer.xlsx', 'Sprengquellen_Tensiometer_unten_nord.xlsx', 'Sprengquellen_Tensiometer_unten_sued.xlsx', \n",
    "                 'Sprengquellen_Tensiometer_oben_nord.xlsx', 'Sprengquellen_Tensiometer_oben_sued.xlsx']\n",
    "\n",
    "# list of all the different stations for ground water level as a csv file\n",
    "FILENAMES_GWL_csv = ['Schafhof_Tensiometer_alt.csv', 'Sprengquellen_Tensiometer_unten_nord_alt.csv', \n",
    "                     'Sprengquellen_Tensiometer_unten_sued_alt.csv', 'Sprengquellen_Tensiometer_oben_nord_alt.csv', \n",
    "                     'Sprengquellen_Tensiometer_oben_sued_alt.csv']\n",
    "\n",
    "# list of all the different stations for river water level as a csv file\n",
    "FILENAMES_RWL_1 = ['Pegel1_Bühlot.csv', 'Pegel1_Schwabenbrünnele.csv', 'Pegel1_Büchelbach.csv']\n",
    "\n",
    "# list of all the different stations for river water level as a csv file\n",
    "FILENAMES_RWL_2 = ['Pegel2_Bühlot.csv', 'Pegel2_Schwabenbrünnele.csv', 'Pegel2_Büchelbach.csv']\n",
    "\n",
    "# list of all the different stations for river water level as a csv file\n",
    "FILENAMES_RWL_4 = ['Pegel4_Bühlot.csv', 'Pegel4_Schwabenbrünnele.csv', 'Pegel4_Büchelbach.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "296903b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [00:06<00:00,  9.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:05<00:00, 12.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:03<00:00,  9.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:06<00:00, 10.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:04<00:00, 10.70it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 69/69 [00:06<00:00, 10.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:04<00:00, 10.05it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:06<00:00,  8.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:06<00:00,  9.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing air temperature and precipitation\n",
    "for filename in FILENAMES:\n",
    "    all_data_AT = []\n",
    "    all_data_P = []\n",
    "    \n",
    "    filenames = glob(f\"*/*/*/{filename}\", recursive=False)\n",
    "    for datafile in tqdm(filenames):\n",
    "        \n",
    "        # preprocess each raw data file, once for rainfall and once for the air temperature\n",
    "        df_AT = preprocessing(datafile, 'air temperature')\n",
    "        df_P = preprocessing(datafile, 'precipitation')\n",
    "        \n",
    "        # append to all_data\n",
    "        all_data_AT.append(df_AT)\n",
    "        all_data_P.append(df_P)\n",
    "\n",
    "    merge('all_data_AT')\n",
    "    merge('all_data_P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0daf45d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:03<00:00, 15.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:03<00:00, 19.55it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:03<00:00, 14.63it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:03<00:00, 18.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing volumetric water content and electric conductivity\n",
    "for filename in FILENAMES_DAT_1:\n",
    "    all_data_VWC_1 = []\n",
    "    all_data_EC_1 = []\n",
    "    \n",
    "    filenames = glob(f\"*/*/*/{filename}\", recursive=False)\n",
    "    for datafile in tqdm(filenames):\n",
    "        \n",
    "        # preprocess each raw data file, once for the volumetric water content and once for the electric conductivity\n",
    "        df_VWC_1 = preprocessing(datafile, 'Table1_VWC')\n",
    "        df_EC_1 = preprocessing(datafile, 'Table1_EC')\n",
    "        \n",
    "        # append to all_data\n",
    "        all_data_VWC_1.append(df_VWC_1)\n",
    "        all_data_EC_1.append(df_EC_1)\n",
    "\n",
    "    merge('all_data_VWC_1')\n",
    "    merge('all_data_EC_1')\n",
    "    \n",
    "for filename in FILENAMES_DAT_2:\n",
    "    all_data_VWC_2 = []\n",
    "    all_data_EC_2 = []\n",
    "    \n",
    "    filenames = glob(f\"*/*/*/{filename}\", recursive=False)\n",
    "    for datafile in tqdm(filenames):\n",
    "        \n",
    "        # preprocess each raw data file, once for the volumetric water content and once for the electric conductivity\n",
    "        df_VWC_2 = preprocessing(datafile, 'Table2_VWC')\n",
    "        df_EC_2 = preprocessing(datafile, 'Table2_EC')\n",
    "        \n",
    "        # append to all_data\n",
    "        all_data_VWC_2.append(df_VWC_2)\n",
    "        all_data_EC_2.append(df_EC_2)\n",
    "\n",
    "    merge('all_data_VWC_2')\n",
    "    merge('all_data_EC_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4539b3cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [01:43<00:00,  2.64s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [01:04<00:00,  3.22s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:15<00:00,  1.58s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [01:33<00:00,  3.13s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [01:28<00:00,  2.69s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.96it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  6.81it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  6.73it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  6.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  5.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing ground water level, water temperature and logger temperature as a xlsx file\n",
    "for filename in FILENAMES_GWL:\n",
    "    all_data_GWL = []\n",
    "    all_data_WT = []\n",
    "    all_data_LT = []\n",
    "    \n",
    "    filenames = glob(f\"*/*/*/{filename}\", recursive=False)\n",
    "    for datafile in tqdm(filenames):\n",
    "        \n",
    "        # preprocess each raw data file\n",
    "        df_GWL = preprocessing(datafile, 'ground water level')\n",
    "        df_WT = preprocessing(datafile, 'water temperature')\n",
    "        df_LT = preprocessing(datafile, 'logger temperature')\n",
    "        \n",
    "        # append to all_data\n",
    "        all_data_GWL.append(df_GWL)\n",
    "        all_data_WT.append(df_WT)\n",
    "        all_data_LT.append(df_LT)\n",
    "\n",
    "    merge('all_data_GWL')\n",
    "    merge('all_data_WT')\n",
    "    merge('all_data_LT')\n",
    "    \n",
    "# preprocessing ground water level, water temperature and logger temperature as a csv file\n",
    "for filename in FILENAMES_GWL_csv:\n",
    "    all_data_GWL_csv = []\n",
    "    all_data_WT_csv = []\n",
    "    all_data_LT_csv = []\n",
    "    \n",
    "    filenames = glob(f\"*/*/*/{filename}\", recursive=False)\n",
    "    for datafile in tqdm(filenames):\n",
    "        \n",
    "        # preprocess each raw data file\n",
    "        df_GWL_csv = preprocessing(datafile, 'ground water level csv')\n",
    "        df_WT_csv = preprocessing(datafile, 'water temperature csv')\n",
    "        df_LT_csv = preprocessing(datafile, 'logger temperature csv')\n",
    "        \n",
    "        # append to all_data\n",
    "        all_data_GWL_csv.append(df_GWL_csv)\n",
    "        all_data_WT_csv.append(df_WT_csv)\n",
    "        all_data_LT_csv.append(df_LT_csv)\n",
    "\n",
    "    merge('all_data_GWL_csv')\n",
    "    merge('all_data_WT_csv')\n",
    "    merge('all_data_LT_csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1b9eceb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:03<00:00,  5.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:03<00:00,  9.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 18.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 16.22it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:02<00:00, 13.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 18.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 14.58it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:02<00:00, 13.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 21.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing river water level as a csv file\n",
    "for filename in FILENAMES_RWL_1:\n",
    "    all_data_RWL_1 = []\n",
    "    \n",
    "    filenames = glob(f\"*/*/*/{filename}\", recursive=False)\n",
    "    for datafile in tqdm(filenames):\n",
    "        \n",
    "        # preprocess each raw data file\n",
    "        df_RWL_1 = preprocessing(datafile, 'river water level 1')\n",
    "\n",
    "        # append to all_data\n",
    "        all_data_RWL_1.append(df_RWL_1)\n",
    "\n",
    "    merge('all_data_RWL_1')\n",
    "\n",
    "for filename in FILENAMES_RWL_2:\n",
    "    all_data_RWL_2 = []\n",
    "    \n",
    "    filenames = glob(f\"*/*/*/{filename}\", recursive=False)\n",
    "    for datafile in tqdm(filenames):\n",
    "        \n",
    "        # preprocess each raw data file\n",
    "        df_RWL_2 = preprocessing(datafile, 'river water level 2')\n",
    "\n",
    "        # append to all_data\n",
    "        all_data_RWL_2.append(df_RWL_2)\n",
    "\n",
    "    merge('all_data_RWL_2')\n",
    "    \n",
    "for filename in FILENAMES_RWL_4:\n",
    "    all_data_RWL_4 = []\n",
    "    \n",
    "    filenames = glob(f\"*/*/*/{filename}\", recursive=False)\n",
    "    for datafile in tqdm(filenames):\n",
    "        \n",
    "        # preprocess each raw data file\n",
    "        df_RWL_4 = preprocessing(datafile, 'river water level 4')\n",
    "\n",
    "        # append to all_data\n",
    "        all_data_RWL_4.append(df_RWL_4)\n",
    "\n",
    "    merge('all_data_RWL_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dd0a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
