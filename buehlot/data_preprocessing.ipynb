{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6600a093",
   "metadata": {},
   "source": [
    "# Bühlot data preprocessing\n",
    "\n",
    "The purpose of this code is to read in all the collected data, sort it by their different variables and then safe it in the correct folder.\n",
    "By running this code ALL the collected data will be processed, not just the new data. Therefore all the previous sorted data will be overwritten. The sorted data will be safed in a folder named \"data_export\".\n",
    "\n",
    "This is a list of all the variables:\n",
    "- discharge [m3/s]\n",
    "- river water level [m]\n",
    "- precipitation [mm]\n",
    "- air temperature [°C]\n",
    "- relative humidity [%]\n",
    "- solar irradiance [W/m2]\n",
    "- wind speed [m/s]\n",
    "- snow water equivalent [mm]\n",
    "- evapotranspiration [mm/d]\n",
    "- volumetric water content [cm3/cm3]\n",
    "- ground water level [m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "808b1fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "from glob import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "758b3e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(filename, variable):\n",
    "    \"\"\"\n",
    "    This function preprocesses the raw data files for the needed variable.\n",
    "    It will seperate a data file into the different variables.\n",
    "    It reads in the raw data to then create a tabel with the columns that are needed. \n",
    "\n",
    "    \"\"\"    \n",
    "\n",
    "    if variable == 'precipitation':\n",
    "        \n",
    "        # read in raw data\n",
    "        df = pd.read_csv(filename, skiprows=1, na_values='Logged')\n",
    "        \n",
    "        # slice down to relevant columns\n",
    "        df = df.iloc[:, [1,3]].copy()\n",
    "\n",
    "        # rename columns\n",
    "        df.columns = ['date_str', 'precipitation']\n",
    "        \n",
    "    elif variable == 'air temperature':\n",
    "        \n",
    "        # read in raw data\n",
    "        df = pd.read_csv(filename, skiprows=1, na_values='Logged')\n",
    "        \n",
    "        # slice down to relevant columns\n",
    "        df = df.iloc[:, [1,2]].copy()\n",
    "        \n",
    "        # rename columns\n",
    "        df.columns = ['date_str', 'air temperature']\n",
    "        \n",
    "    elif variable == 'Table1_VWC':\n",
    "        \n",
    "        # read in raw data from table 1\n",
    "        df = pd.read_csv(filename, skiprows=[1,2,3,4], na_values='Logged')\n",
    "\n",
    "        # slice down to relevant columns\n",
    "        df = df.iloc[:, [0,2]].copy()\n",
    "\n",
    "        # rename columns\n",
    "        df.columns = ['date_str', 'volumetric water content [m^3/m^3; %]']\n",
    "        \n",
    "    elif variable == 'Table1_EC':\n",
    "        \n",
    "        # read in raw data from table 1\n",
    "        df = pd.read_csv(filename, skiprows=[1,2,3,4], na_values='Logged')\n",
    "\n",
    "        # slice down to relevant columns\n",
    "        df = df.iloc[:, [0,3]].copy()\n",
    "\n",
    "        # rename columns\n",
    "        df.columns = ['date_str', 'electric conductivity [dS/m]']\n",
    "        \n",
    "    elif variable == 'Table2_VWC':\n",
    "        \n",
    "        # read in raw data from table 2\n",
    "        df = pd.read_csv(filename, skiprows=[1,2,3,4], na_values='Logged')\n",
    "\n",
    "        # slice down to relevant columns\n",
    "        df = df.iloc[:, [0,3]].copy()\n",
    "\n",
    "        # rename columns\n",
    "        df.columns = ['date_str', 'volumetric water content [m^3/m^3; %]']\n",
    "        \n",
    "    elif variable == 'Table2_EC':\n",
    "        \n",
    "        # read in raw data from table 2\n",
    "        df = pd.read_csv(filename, skiprows=[1,2,3,4], na_values='Logged')\n",
    "\n",
    "        # slice down to relevant columns\n",
    "        df = df.iloc[:, [0,4]].copy()\n",
    "\n",
    "        # rename columns\n",
    "        df.columns = ['date_str', 'electric conductivity [dS/m]']\n",
    "        \n",
    "    elif variable == 'ground water level':\n",
    "        \n",
    "        # read in raw data\n",
    "        df = pd.read_excel(filename, skiprows=[1,2,3,4,5,6,7,8,9,10,11], na_values='Logged')\n",
    "\n",
    "        # slice down to relevant columns\n",
    "        df = df.iloc[:, [1,4]].copy()\n",
    "\n",
    "        # rename columns\n",
    "        df.columns = ['date_str', 'water height [mm]']\n",
    "        \n",
    "    elif variable == 'water temperature':\n",
    "        \n",
    "        # read in raw data\n",
    "        df = pd.read_excel(filename, skiprows=[1,2,3,4,5,6,7,8,9,10,11], na_values='Logged')\n",
    "\n",
    "        # slice down to relevant columns\n",
    "        df = df.iloc[:, [1,2]].copy()\n",
    "\n",
    "        # rename columns\n",
    "        df.columns = ['date_str', 'water temperature [°C]']\n",
    "        \n",
    "    elif variable == 'logger temperature':\n",
    "        \n",
    "        # read in raw data\n",
    "        df = pd.read_excel(filename, skiprows=[1,2,3,4,5,6,7,8,9,10,11], na_values='Logged')\n",
    "\n",
    "        # slice down to relevant columns\n",
    "        df = df.iloc[:, [1,3]].copy()\n",
    "\n",
    "        # rename columns\n",
    "        df.columns = ['date_str', 'logger temperature [°C]']\n",
    "        \n",
    "    elif variable == 'ground water level csv':\n",
    "        \n",
    "        # read in raw data\n",
    "        df = pd.read_csv(filename, na_values='Logged')\n",
    "\n",
    "        # slice down to relevant columns\n",
    "        df = df.iloc[:, [1,4]].copy()\n",
    "\n",
    "        # rename columns\n",
    "        df.columns = ['date_str', 'water height [mm]']\n",
    "        \n",
    "    elif variable == 'water temperature csv':\n",
    "        \n",
    "        # read in raw data\n",
    "        df = pd.read_csv(filename, na_values='Logged')\n",
    "\n",
    "        # slice down to relevant columns\n",
    "        df = df.iloc[:, [1,2]].copy()\n",
    "\n",
    "        # rename columns\n",
    "        df.columns = ['date_str', 'water temperature [°C]']\n",
    "        \n",
    "    elif variable == 'logger temperature csv':\n",
    "        \n",
    "        # read in raw data\n",
    "        df = pd.read_csv(filename, na_values='Logged')\n",
    "\n",
    "        # slice down to relevant columns\n",
    "        df = df.iloc[:, [1,3]].copy()\n",
    "\n",
    "        # rename columns\n",
    "        df.columns = ['date_str', 'logger temperature [°C]']\n",
    "        \n",
    "    elif variable == 'river water level 1':\n",
    "        \n",
    "        # read in raw data\n",
    "        df = pd.read_csv(filename, na_values='Logged', sep=';', header=None)\n",
    "\n",
    "        # rename columns\n",
    "        df.columns = ['date_str', 'time', 'river water level 1 []']\n",
    "        \n",
    "    elif variable == 'river water level 2':\n",
    "        \n",
    "        # read in raw data\n",
    "        df = pd.read_csv(filename, na_values='Logged', sep=';', header=None)\n",
    "\n",
    "        # rename columns\n",
    "        df.columns = ['date_str', 'time', 'river water level 2 []']\n",
    "        \n",
    "    elif variable == 'river water level 4':\n",
    "        \n",
    "        # read in raw data\n",
    "        df = pd.read_csv(filename, na_values='Logged', sep=';', header=None)\n",
    "\n",
    "        # rename columns\n",
    "        df.columns = ['date_str', 'time', 'river water level 4 []']\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Variable is '{variable}', must be in ['precipitation', 'air temperature', 'Table1_VWC', 'Table1_EC', 'Table2_VWC', 'Table2_EC', 'ground water level', 'water temperature', 'logger temperature', 'ground water level csv', 'water temperature csv', 'logger temperature csv', 'river water level 1', 'river water level 2', 'river water level 4']\")\n",
    "    \n",
    "    # return preprocessed dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3751058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(variable):\n",
    "    \"\"\"\n",
    "    This function merges all the data for the assigned list. \n",
    "    Here it is one list for the variable \"air temperature\" and one for the variable \"precipitation\". \n",
    "    It also will create a list for the sensor \"Table1\" and one for the sensor \"Table2\".\n",
    "    It will sort the lists by datetime and then safe the files in the right folder.\n",
    "    \n",
    "    \"Table1\" and \"Table2\" are names from the data file volumetric water content. Each station has two sensors (\"Table1\" and \"Table2\"). \n",
    "    While the sensor from \"Table1\" is placed in a depth of 20 cm below the top edge of the ground, the other sensor \"Table2\" is placed in a \n",
    "    depth of 50 cm below the top edge of the ground.\n",
    "    \n",
    "    The abbreviations are:\n",
    "    AT = air temperature\n",
    "    P = precipitation\n",
    "    VWC_1 = volumetric water content of \"Table1\"\n",
    "    EC_1 = electric conductivity of \"Table1\"\n",
    "    VWC_2 = volumetric water content of \"Table2\"\n",
    "    EC_2 = electric conductivity of \"Table2\"\n",
    "    GWL = ground water level as a .xlsx file\n",
    "    WT = water temperature as a .xlsx file\n",
    "    LT = logger temperature as a .xlsx file\n",
    "    GWL_csv = ground water level as a .csv file\n",
    "    WT_csv = water temperature as a .csv file\n",
    "    LG_csv = logger temperature as a .csv file \n",
    "    RWL_1 = river water level from the first sensor\n",
    "    RWL_2 = river water level from the second sensor\n",
    "    RWL_4 = river water level from the third sensor - sensor is named with number 4 \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if variable == 'all_data_AT':\n",
    "        \n",
    "        # merge all_data\n",
    "        df_all_data_AT = pd.concat(all_data_AT, ignore_index=True)\n",
    "        \n",
    "        # sort by datetime\n",
    "        df_all_data_AT.sort_index(axis='index', inplace=False)\n",
    "        \n",
    "        # replace filename \n",
    "        filename_AT = filename.replace(\".csv\", \"_air_temperature.csv\")\n",
    "        \n",
    "        # safe file to csv in the right folder\n",
    "        df_all_data_AT.to_csv(f'data_export/air_temperature/{filename_AT}', index=False)\n",
    "        \n",
    "    elif variable == 'all_data_P':\n",
    "        \n",
    "        # merge all_data\n",
    "        df_all_data_P = pd.concat(all_data_P, ignore_index=True)\n",
    "        \n",
    "        # sort by datetime\n",
    "        df_all_data_P.sort_index(axis='index', inplace=False)\n",
    "        \n",
    "        # replace filename\n",
    "        filename_P = filename.replace(\".csv\", \"_precipitation.csv\")\n",
    "        \n",
    "        # safe file to csv in the right folder\n",
    "        df_all_data_P.to_csv(f'data_export/precipitation/{filename_P}', index=False)\n",
    "        \n",
    "    elif variable == 'all_data_VWC_1':\n",
    "        \n",
    "        # merge all_data\n",
    "        df_all_data_VWC_1 = pd.concat(all_data_VWC_1, ignore_index=True)\n",
    "        \n",
    "        # sort by datetime\n",
    "        df_all_data_VWC_1.sort_index(axis='index', inplace=False)\n",
    "        \n",
    "        # replace filename\n",
    "        filename_VWC_1 = filename.replace(\".dat\", \"_VWC.dat\")\n",
    "        \n",
    "        # safe file to csv in the right folder\n",
    "        df_all_data_VWC_1.to_csv(f'data_export/volumetric_water_content/{filename_VWC_1}', index=False)\n",
    "        \n",
    "    elif variable == 'all_data_EC_1':\n",
    "        \n",
    "        # merge all_data\n",
    "        df_all_data_EC_1 = pd.concat(all_data_EC_1, ignore_index=True)\n",
    "        \n",
    "        # sort by datetime\n",
    "        df_all_data_EC_1.sort_index(axis='index', inplace=False)\n",
    "        \n",
    "        # replace filename\n",
    "        filename_EC_1 = filename.replace(\".dat\", \"_EC.dat\")\n",
    "        \n",
    "        # safe file to csv in the right folder\n",
    "        df_all_data_EC_1.to_csv(f'data_export/electric_conductivity/{filename_EC_1}', index=False)\n",
    "        \n",
    "    elif variable == 'all_data_VWC_2':\n",
    "        \n",
    "        # merge all_data\n",
    "        df_all_data_VWC_2 = pd.concat(all_data_VWC_2, ignore_index=True)\n",
    "        \n",
    "        # sort by datetime\n",
    "        df_all_data_VWC_2.sort_index(axis='index', inplace=False)\n",
    "        \n",
    "        # replace filename\n",
    "        filename_VWC_2 = filename.replace(\".dat\", \"_VWC.dat\")\n",
    "        \n",
    "        # safe file to csv in the right folder\n",
    "        df_all_data_VWC_2.to_csv(f'data_export/volumetric_water_content/{filename_VWC_2}', index=False)\n",
    "        \n",
    "    elif variable == 'all_data_EC_2':\n",
    "        \n",
    "        # merge all_data\n",
    "        df_all_data_EC_2 = pd.concat(all_data_EC_2, ignore_index=True)\n",
    "        \n",
    "        # sort by datetime\n",
    "        df_all_data_EC_2.sort_index(axis='index', inplace=False)\n",
    "        \n",
    "        # replace filename\n",
    "        filename_EC_2 = filename.replace(\".dat\", \"_EC.dat\")\n",
    "        \n",
    "        # safe file to csv in the right folder\n",
    "        df_all_data_EC_2.to_csv(f'data_export/electric_conductivity/{filename_EC_2}', index=False)\n",
    "        \n",
    "    elif variable == 'all_data_GWL':\n",
    "        \n",
    "        # merge all_data\n",
    "        df_all_data_GWL = pd.concat(all_data_GWL, ignore_index=True)\n",
    "        \n",
    "        # sort by datetime\n",
    "        df_all_data_GWL.sort_index(axis='index', inplace=False)\n",
    "        \n",
    "        # replace filename\n",
    "        filename_GWL = filename.replace(\".xlsx\", \"_GWL.xlsx\")\n",
    "        \n",
    "        # safe file to csv in the right folder\n",
    "        df_all_data_GWL.to_excel(f'data_export/ground_water_level/{filename_GWL}', index=False)\n",
    "        \n",
    "    elif variable == 'all_data_WT':\n",
    "        \n",
    "        # merge all_data\n",
    "        df_all_data_WT = pd.concat(all_data_WT, ignore_index=True)\n",
    "        \n",
    "        # sort by datetime\n",
    "        df_all_data_WT.sort_index(axis='index', inplace=False)\n",
    "        \n",
    "        # replace filename\n",
    "        filename_WT = filename.replace(\".xlsx\", \"_WT.xlsx\")\n",
    "        \n",
    "        # safe file to csv in the right folder\n",
    "        df_all_data_WT.to_excel(f'data_export/water_temperature/{filename_WT}', index=False)\n",
    "        \n",
    "    elif variable == 'all_data_LT':\n",
    "        \n",
    "        # merge all_data\n",
    "        df_all_data_LT = pd.concat(all_data_LT, ignore_index=True)\n",
    "        \n",
    "        # sort by datetime\n",
    "        df_all_data_LT.sort_index(axis='index', inplace=False)\n",
    "        \n",
    "        # replace filename\n",
    "        filename_LT = filename.replace(\".xlsx\", \"_LT.xlsx\")\n",
    "        \n",
    "        # safe file to csv in the right folder\n",
    "        df_all_data_LT.to_excel(f'data_export/logger_temperature/{filename_LT}', index=False)\n",
    "        \n",
    "    elif variable == 'all_data_GWL_csv':\n",
    "        \n",
    "        # merge all_data\n",
    "        df_all_data_GWL_csv = pd.concat(all_data_GWL_csv, ignore_index=True)\n",
    "        \n",
    "        # sort by datetime\n",
    "        df_all_data_GWL_csv.sort_index(axis='index', inplace=False)\n",
    "        \n",
    "        # replace filename\n",
    "        filename_GWL_csv = filename.replace(\".csv\", \"_GWL.csv\")\n",
    "        \n",
    "        # safe file to csv in the right folder\n",
    "        df_all_data_GWL_csv.to_csv(f'data_export/ground_water_level/{filename_GWL_csv}', index=False)\n",
    "        \n",
    "    elif variable == 'all_data_WT_csv':\n",
    "        \n",
    "        # merge all_data\n",
    "        df_all_data_WT_csv = pd.concat(all_data_WT_csv, ignore_index=True)\n",
    "        \n",
    "        # sort by datetime\n",
    "        df_all_data_WT_csv.sort_index(axis='index', inplace=False)\n",
    "        \n",
    "        # replace filename\n",
    "        filename_WT_csv = filename.replace(\".csv\", \"_WT.csv\")\n",
    "        \n",
    "        # safe file to csv in the right folder\n",
    "        df_all_data_WT_csv.to_csv(f'data_export/water_temperature/{filename_WT_csv}', index=False)\n",
    "        \n",
    "    elif variable == 'all_data_LT_csv':\n",
    "        \n",
    "        # merge all_data\n",
    "        df_all_data_LT_csv = pd.concat(all_data_LT_csv, ignore_index=True)\n",
    "        \n",
    "        # sort by datetime\n",
    "        df_all_data_LT_csv.sort_index(axis='index', inplace=False)\n",
    "        \n",
    "        # replace filename\n",
    "        filename_LT_csv = filename.replace(\".csv\", \"_LT.csv\")\n",
    "        \n",
    "        # safe file to csv in the right folder\n",
    "        df_all_data_LT_csv.to_csv(f'data_export/logger_temperature/{filename_LT_csv}', index=False)\n",
    "        \n",
    "    elif variable == 'all_data_RWL_1':\n",
    "        \n",
    "        # merge all_data\n",
    "        df_all_data_RWL_1 = pd.concat(all_data_RWL_1, ignore_index=True)\n",
    "        \n",
    "        # sort by datetime\n",
    "        df_all_data_RWL_1.sort_index(axis='index', inplace=False)\n",
    "        \n",
    "        # replace filename\n",
    "        filename_RWL_1 = filename.replace(\".csv\", \"_RWL_1.csv\")\n",
    "        \n",
    "        # safe file to csv in the right folder\n",
    "        df_all_data_RWL_1.to_csv(f'data_export/river_water_level_1/{filename_RWL_1}', index=False)\n",
    "        \n",
    "    elif variable == 'all_data_RWL_2':\n",
    "        \n",
    "        # merge all_data\n",
    "        df_all_data_RWL_2 = pd.concat(all_data_RWL_2, ignore_index=True)\n",
    "        \n",
    "        # sort by datetime\n",
    "        df_all_data_RWL_2.sort_index(axis='index', inplace=False)\n",
    "        \n",
    "        # replace filename\n",
    "        filename_RWL_2 = filename.replace(\".csv\", \"_RWL_2.csv\")\n",
    "        \n",
    "        # safe file to csv in the right folder\n",
    "        df_all_data_RWL_2.to_csv(f'data_export/river_water_level_2/{filename_RWL_2}', index=False)\n",
    "        \n",
    "    elif variable == 'all_data_RWL_4':\n",
    "        \n",
    "        # merge all_data\n",
    "        df_all_data_RWL_4 = pd.concat(all_data_RWL_4, ignore_index=True)\n",
    "        \n",
    "        # sort by datetime\n",
    "        df_all_data_RWL_4.sort_index(axis='index', inplace=False)\n",
    "        \n",
    "        # replace filename\n",
    "        filename_RWL_4 = filename.replace(\".csv\", \"_RWL_4.csv\")\n",
    "        \n",
    "        # safe file to csv in the right folder\n",
    "        df_all_data_RWL_4.to_csv(f'data_export/river_water_level_4/{filename_RWL_4}', index=False)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Variable is '{variable}', must be in ['all_data_AT', 'all_data_P', 'all_data_VWC_1', 'all_data_EC_1', 'all_data_VWC_2', 'all_data_EC_2', 'all_data_GWL', 'all_data_WT', 'all_data_LT', 'all_data_GWL_csv', 'all_data_WT_csv', 'all_data_LT_csv', 'river water level 1', 'river water level 2', 'river water level 4']\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05ab14ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all the different stations for precipitation and air temperature\n",
    "FILENAMES = ['Butschenberg.csv', 'Grundigklinik.csv', 'Hundseck.csv', 'Schafhof.csv', 'Schönbrunn.csv', 'Sportplatz.csv', \n",
    "             'Sternenberg-Schlammfang.csv', 'Schwabenquelle.csv', 'Winterberg.csv']\n",
    "\n",
    "# lists of all the different stations for soil moisture \n",
    "FILENAMES_DAT_1 = ['Schafhof1_Table1.dat', 'Schafhof5_Table1.dat']\n",
    "FILENAMES_DAT_2 = ['Schafhof1_Table2.dat', 'Schafhof5_Table2.dat']\n",
    "\n",
    "# list of all the different stations for ground water level as a xlsx file\n",
    "FILENAMES_GWL = ['Schafhof_Tensiometer.xlsx', 'Sprengquellen_Tensiometer_unten_nord.xlsx', 'Sprengquellen_Tensiometer_unten_sued.xlsx', \n",
    "                 'Sprengquellen_Tensiometer_oben_nord.xlsx', 'Sprengquellen_Tensiometer_oben_sued.xlsx']\n",
    "\n",
    "# list of all the different stations for ground water level as a csv file\n",
    "FILENAMES_GWL_csv = ['Schafhof_Tensiometer_alt.csv', 'Sprengquellen_Tensiometer_unten_nord_alt.csv', \n",
    "                     'Sprengquellen_Tensiometer_unten_sued_alt.csv', 'Sprengquellen_Tensiometer_oben_nord_alt.csv', \n",
    "                     'Sprengquellen_Tensiometer_oben_sued_alt.csv']\n",
    "\n",
    "# list of all the different stations for river water level as a csv file\n",
    "FILENAMES_RWL_1 = ['Pegel1_Bühlot.csv', 'Pegel1_Schwabenbrünnele.csv', 'Pegel1_Büchelbach.csv']\n",
    "\n",
    "# list of all the different stations for river water level as a csv file\n",
    "FILENAMES_RWL_2 = ['Pegel2_Bühlot.csv', 'Pegel2_Schwabenbrünnele.csv', 'Pegel2_Büchelbach.csv']\n",
    "\n",
    "# list of all the different stations for river water level as a csv file\n",
    "FILENAMES_RWL_4 = ['Pegel4_Bühlot.csv', 'Pegel4_Schwabenbrünnele.csv', 'Pegel4_Büchelbach.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "296903b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [00:02<00:00, 26.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:02<00:00, 27.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 22.29it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 24.93it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 27.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 69/69 [00:02<00:00, 25.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 27.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:02<00:00, 24.88it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:02<00:00, 23.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing air temperature and precipitation\n",
    "for filename in FILENAMES:\n",
    "    all_data_AT = []\n",
    "    all_data_P = []\n",
    "    \n",
    "    filenames = glob(f\"*/*/{filename}\", recursive=False)\n",
    "    for datafile in tqdm(filenames):\n",
    "        \n",
    "        # preprocess each raw data file, once for rainfall and once for the air temperature\n",
    "        df_AT = preprocessing(datafile, 'air temperature')\n",
    "        df_P = preprocessing(datafile, 'precipitation')\n",
    "        \n",
    "        # append to all_data\n",
    "        all_data_AT.append(df_AT)\n",
    "        all_data_P.append(df_P)\n",
    "\n",
    "    merge('all_data_AT')\n",
    "    merge('all_data_P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0daf45d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 22.31it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:02<00:00, 27.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 21.09it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 25.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing volumetric water content and electric conductivity\n",
    "for filename in FILENAMES_DAT_1:\n",
    "    all_data_VWC_1 = []\n",
    "    all_data_EC_1 = []\n",
    "    \n",
    "    filenames = glob(f\"*/*/{filename}\", recursive=False)\n",
    "    for datafile in tqdm(filenames):\n",
    "        \n",
    "        # preprocess each raw data file, once for the volumetric water content and once for the electric conductivity\n",
    "        df_VWC_1 = preprocessing(datafile, 'Table1_VWC')\n",
    "        df_EC_1 = preprocessing(datafile, 'Table1_EC')\n",
    "        \n",
    "        # append to all_data\n",
    "        all_data_VWC_1.append(df_VWC_1)\n",
    "        all_data_EC_1.append(df_EC_1)\n",
    "\n",
    "    merge('all_data_VWC_1')\n",
    "    merge('all_data_EC_1')\n",
    "    \n",
    "for filename in FILENAMES_DAT_2:\n",
    "    all_data_VWC_2 = []\n",
    "    all_data_EC_2 = []\n",
    "    \n",
    "    filenames = glob(f\"*/*/{filename}\", recursive=False)\n",
    "    for datafile in tqdm(filenames):\n",
    "        \n",
    "        # preprocess each raw data file, once for the volumetric water content and once for the electric conductivity\n",
    "        df_VWC_2 = preprocessing(datafile, 'Table2_VWC')\n",
    "        df_EC_2 = preprocessing(datafile, 'Table2_EC')\n",
    "        \n",
    "        # append to all_data\n",
    "        all_data_VWC_2.append(df_VWC_2)\n",
    "        all_data_EC_2.append(df_EC_2)\n",
    "\n",
    "    merge('all_data_VWC_2')\n",
    "    merge('all_data_EC_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4539b3cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [01:39<00:00,  2.55s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:55<00:00,  2.78s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:18<00:00,  1.82s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [01:30<00:00,  3.03s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [01:38<00:00,  3.00s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 21.90it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 19.82it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 19.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 17.89it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 17.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing ground water level, water temperature and logger temperature as a xlsx file\n",
    "for filename in FILENAMES_GWL:\n",
    "    all_data_GWL = []\n",
    "    all_data_WT = []\n",
    "    all_data_LT = []\n",
    "    \n",
    "    filenames = glob(f\"*/*/{filename}\", recursive=False)\n",
    "    for datafile in tqdm(filenames):\n",
    "        \n",
    "        # preprocess each raw data file\n",
    "        df_GWL = preprocessing(datafile, 'ground water level')\n",
    "        df_WT = preprocessing(datafile, 'water temperature')\n",
    "        df_LT = preprocessing(datafile, 'logger temperature')\n",
    "        \n",
    "        # append to all_data\n",
    "        all_data_GWL.append(df_GWL)\n",
    "        all_data_WT.append(df_WT)\n",
    "        all_data_LT.append(df_LT)\n",
    "\n",
    "    merge('all_data_GWL')\n",
    "    merge('all_data_WT')\n",
    "    merge('all_data_LT')\n",
    "    \n",
    "# preprocessing ground water level, water temperature and logger temperature as a csv file\n",
    "for filename in FILENAMES_GWL_csv:\n",
    "    all_data_GWL_csv = []\n",
    "    all_data_WT_csv = []\n",
    "    all_data_LT_csv = []\n",
    "    \n",
    "    filenames = glob(f\"*/*/{filename}\", recursive=False)\n",
    "    for datafile in tqdm(filenames):\n",
    "        \n",
    "        # preprocess each raw data file\n",
    "        df_GWL_csv = preprocessing(datafile, 'ground water level csv')\n",
    "        df_WT_csv = preprocessing(datafile, 'water temperature csv')\n",
    "        df_LT_csv = preprocessing(datafile, 'logger temperature csv')\n",
    "        \n",
    "        # append to all_data\n",
    "        all_data_GWL_csv.append(df_GWL_csv)\n",
    "        all_data_WT_csv.append(df_WT_csv)\n",
    "        all_data_LT_csv.append(df_LT_csv)\n",
    "\n",
    "    merge('all_data_GWL_csv')\n",
    "    merge('all_data_WT_csv')\n",
    "    merge('all_data_LT_csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b9eceb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 54.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 76.55it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 52.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 58.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 50.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 46.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 48.38it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 48.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 61.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing river water level as a csv file\n",
    "for filename in FILENAMES_RWL_1:\n",
    "    all_data_RWL_1 = []\n",
    "    \n",
    "    filenames = glob(f\"*/*/{filename}\", recursive=False)\n",
    "    for datafile in tqdm(filenames):\n",
    "        \n",
    "        # preprocess each raw data file\n",
    "        df_RWL_1 = preprocessing(datafile, 'river water level 1')\n",
    "\n",
    "        # append to all_data\n",
    "        all_data_RWL_1.append(df_RWL_1)\n",
    "\n",
    "    merge('all_data_RWL_1')\n",
    "\n",
    "for filename in FILENAMES_RWL_2:\n",
    "    all_data_RWL_2 = []\n",
    "    \n",
    "    filenames = glob(f\"*/*/{filename}\", recursive=False)\n",
    "    for datafile in tqdm(filenames):\n",
    "        \n",
    "        # preprocess each raw data file\n",
    "        df_RWL_2 = preprocessing(datafile, 'river water level 2')\n",
    "\n",
    "        # append to all_data\n",
    "        all_data_RWL_2.append(df_RWL_2)\n",
    "\n",
    "    merge('all_data_RWL_2')\n",
    "    \n",
    "for filename in FILENAMES_RWL_4:\n",
    "    all_data_RWL_4 = []\n",
    "    \n",
    "    filenames = glob(f\"*/*/{filename}\", recursive=False)\n",
    "    for datafile in tqdm(filenames):\n",
    "        \n",
    "        # preprocess each raw data file\n",
    "        df_RWL_4 = preprocessing(datafile, 'river water level 4')\n",
    "\n",
    "        # append to all_data\n",
    "        all_data_RWL_4.append(df_RWL_4)\n",
    "\n",
    "    merge('all_data_RWL_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d1d15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Die nächsten Zeilen habe ich noch nicht gelöscht, da ich diese noch dem Alex zeigen möchte.\n",
    "Ich habe aus den Tabellen wirklich nur den volumetrischen Wassergehalt rausgeholt, da die anderen Variablen nicht in der Liste stehen\n",
    "die er mir mal per Mail geschickt hat.\n",
    "Ist das richtig so?\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0e556a6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_str</th>\n",
       "      <th>volumetric water content [m^3/m^3; %]</th>\n",
       "      <th>electric conductivity [dS/m]</th>\n",
       "      <th>temperature [°C]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-05 01:00:00</td>\n",
       "      <td>0.2493</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>15.5418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-05 01:05:00</td>\n",
       "      <td>0.2492</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>15.5336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-05 01:10:00</td>\n",
       "      <td>0.2492</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>15.5143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-05 01:15:00</td>\n",
       "      <td>0.2492</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>15.5143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-05 01:20:00</td>\n",
       "      <td>0.2492</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>15.4867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13066</th>\n",
       "      <td>2023-11-19 09:50:00</td>\n",
       "      <td>0.3830</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>8.8431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13067</th>\n",
       "      <td>2023-11-19 09:55:00</td>\n",
       "      <td>0.3830</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>8.8633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13068</th>\n",
       "      <td>2023-11-19 10:00:00</td>\n",
       "      <td>0.3828</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>8.8691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13069</th>\n",
       "      <td>2023-11-19 10:05:00</td>\n",
       "      <td>0.3828</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>8.8980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13070</th>\n",
       "      <td>2023-11-19 10:10:00</td>\n",
       "      <td>0.3828</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>8.8720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13071 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date_str  volumetric water content [m^3/m^3; %]  \\\n",
       "0      2023-10-05 01:00:00                                 0.2493   \n",
       "1      2023-10-05 01:05:00                                 0.2492   \n",
       "2      2023-10-05 01:10:00                                 0.2492   \n",
       "3      2023-10-05 01:15:00                                 0.2492   \n",
       "4      2023-10-05 01:20:00                                 0.2492   \n",
       "...                    ...                                    ...   \n",
       "13066  2023-11-19 09:50:00                                 0.3830   \n",
       "13067  2023-11-19 09:55:00                                 0.3830   \n",
       "13068  2023-11-19 10:00:00                                 0.3828   \n",
       "13069  2023-11-19 10:05:00                                 0.3828   \n",
       "13070  2023-11-19 10:10:00                                 0.3828   \n",
       "\n",
       "       electric conductivity [dS/m]  temperature [°C]  \n",
       "0                            0.0058           15.5418  \n",
       "1                            0.0061           15.5336  \n",
       "2                            0.0060           15.5143  \n",
       "3                            0.0059           15.5143  \n",
       "4                            0.0060           15.4867  \n",
       "...                             ...               ...  \n",
       "13066                        0.0072            8.8431  \n",
       "13067                        0.0073            8.8633  \n",
       "13068                        0.0074            8.8691  \n",
       "13069                        0.0073            8.8980  \n",
       "13070                        0.0072            8.8720  \n",
       "\n",
       "[13071 rows x 4 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in raw data from table 1\n",
    "df = pd.read_csv('Daten-2023/11_19_23/Schafhof5_Table1.dat', skiprows=[1,2,3,4], na_values='Logged')\n",
    "\n",
    "# slice down to relevant columns\n",
    "df = df.iloc[:, [0,2,3,4]].copy()\n",
    "\n",
    "# rename columns\n",
    "df.columns = ['date_str', 'volumetric water content [m^3/m^3; %]', 'electric conductivity [dS/m]', 'temperature [°C]']\n",
    "        \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c2aada82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_str</th>\n",
       "      <th>battery voltage [volts]</th>\n",
       "      <th>volumetric water content [m^3/m^3; %]</th>\n",
       "      <th>electric conductivity [dS/m]</th>\n",
       "      <th>temperature [°C]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-05 01:20:00</td>\n",
       "      <td>12.91225</td>\n",
       "      <td>0.2603</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>16.1330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-05 01:25:00</td>\n",
       "      <td>12.91309</td>\n",
       "      <td>0.2603</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>16.1138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-05 01:30:00</td>\n",
       "      <td>12.91309</td>\n",
       "      <td>0.2603</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>16.0973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-05 01:35:00</td>\n",
       "      <td>12.89798</td>\n",
       "      <td>0.2603</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>16.0973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-05 01:40:00</td>\n",
       "      <td>12.91393</td>\n",
       "      <td>0.2603</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>16.1111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13062</th>\n",
       "      <td>2023-11-19 09:50:00</td>\n",
       "      <td>12.89294</td>\n",
       "      <td>0.3321</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>10.0701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13063</th>\n",
       "      <td>2023-11-19 09:55:00</td>\n",
       "      <td>12.88958</td>\n",
       "      <td>0.3321</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>10.0815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13064</th>\n",
       "      <td>2023-11-19 10:00:00</td>\n",
       "      <td>12.89546</td>\n",
       "      <td>0.3318</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>10.1101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13065</th>\n",
       "      <td>2023-11-19 10:05:00</td>\n",
       "      <td>12.89378</td>\n",
       "      <td>0.3318</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>10.0587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13066</th>\n",
       "      <td>2023-11-19 10:10:00</td>\n",
       "      <td>12.88874</td>\n",
       "      <td>0.3318</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>10.0901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13067 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date_str  battery voltage [volts]  \\\n",
       "0      2023-10-05 01:20:00                 12.91225   \n",
       "1      2023-10-05 01:25:00                 12.91309   \n",
       "2      2023-10-05 01:30:00                 12.91309   \n",
       "3      2023-10-05 01:35:00                 12.89798   \n",
       "4      2023-10-05 01:40:00                 12.91393   \n",
       "...                    ...                      ...   \n",
       "13062  2023-11-19 09:50:00                 12.89294   \n",
       "13063  2023-11-19 09:55:00                 12.88958   \n",
       "13064  2023-11-19 10:00:00                 12.89546   \n",
       "13065  2023-11-19 10:05:00                 12.89378   \n",
       "13066  2023-11-19 10:10:00                 12.88874   \n",
       "\n",
       "       volumetric water content [m^3/m^3; %]  electric conductivity [dS/m]  \\\n",
       "0                                     0.2603                        0.0011   \n",
       "1                                     0.2603                        0.0011   \n",
       "2                                     0.2603                        0.0011   \n",
       "3                                     0.2603                        0.0012   \n",
       "4                                     0.2603                        0.0011   \n",
       "...                                      ...                           ...   \n",
       "13062                                 0.3321                        0.0014   \n",
       "13063                                 0.3321                        0.0013   \n",
       "13064                                 0.3318                        0.0016   \n",
       "13065                                 0.3318                        0.0014   \n",
       "13066                                 0.3318                        0.0016   \n",
       "\n",
       "       temperature [°C]  \n",
       "0               16.1330  \n",
       "1               16.1138  \n",
       "2               16.0973  \n",
       "3               16.0973  \n",
       "4               16.1111  \n",
       "...                 ...  \n",
       "13062           10.0701  \n",
       "13063           10.0815  \n",
       "13064           10.1101  \n",
       "13065           10.0587  \n",
       "13066           10.0901  \n",
       "\n",
       "[13067 rows x 5 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in raw data from table 2\n",
    "df = pd.read_csv('Daten-2023/11_19_23/Schafhof5_Table2.dat', skiprows=[1,2,3,4], na_values='Logged')\n",
    "\n",
    "# slice down to relevant columns\n",
    "df = df.iloc[:, [0,2,3,4,5]].copy()\n",
    "\n",
    "# rename columns\n",
    "df.columns = ['date_str', 'battery voltage [volts]', 'volumetric water content [m^3/m^3; %]', 'electric conductivity [dS/m]', \n",
    "              'temperature [°C]']\n",
    "        \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b1bca8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHier werde ich die Tabellen für die Tensiometer anzeigen lassen.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Hier werde ich die Tabellen für die Pegel anzeigen lassen.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a50d60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tstamp</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-02-29 00:05:00</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-02-29 00:10:00</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-02-29 00:15:00</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-02-29 00:20:00</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-02-29 00:25:00</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8635</th>\n",
       "      <td>2016-03-29 23:40:00</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8636</th>\n",
       "      <td>2016-03-29 23:45:00</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8637</th>\n",
       "      <td>2016-03-29 23:50:00</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8638</th>\n",
       "      <td>2016-03-29 23:55:00</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8639</th>\n",
       "      <td>2016-03-30 00:00:00</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  tstamp     2\n",
       "0    2016-02-29 00:05:00  0.08\n",
       "1    2016-02-29 00:10:00  0.08\n",
       "2    2016-02-29 00:15:00  0.08\n",
       "3    2016-02-29 00:20:00  0.08\n",
       "4    2016-02-29 00:25:00  0.08\n",
       "...                  ...   ...\n",
       "8635 2016-03-29 23:40:00   ---\n",
       "8636 2016-03-29 23:45:00   ---\n",
       "8637 2016-03-29 23:50:00   ---\n",
       "8638 2016-03-29 23:55:00   ---\n",
       "8639 2016-03-30 00:00:00   ---\n",
       "\n",
       "[8640 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in raw data from table 2\n",
    "df = pd.read_csv('Daten-2016/Daten-03-29/Pegel4_Büchelbach.csv', na_values='Logged', sep=';', header=None)\n",
    "\n",
    "\n",
    "# merge date with time\n",
    "df['tstamp'] = df.iloc[:,0] + ' ' + df.iloc[:,1]\n",
    "\n",
    "# rename columns\n",
    "#df.columns = ['date_str', 'time', 'sensor']\n",
    "\n",
    "# convert to datetime\n",
    "df['tstamp'] = pd.to_datetime(df['tstamp'], format='%d.%m.%Y %H:%M')\n",
    "\n",
    "df = df[['tstamp', 2]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ca3ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_str to tstamp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
